{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6777,"status":"ok","timestamp":1704771085626,"user":{"displayName":"liu rongchuan","userId":"03500046369369319821"},"user_tz":-480},"id":"j5bJlIGSs3lj","outputId":"6bb615c7-f04a-4194-89c0-c1792c129c39"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8623,"status":"ok","timestamp":1704727147942,"user":{"displayName":"liu rongchuan","userId":"03500046369369319821"},"user_tz":-480},"id":"NzIdkQEOdqa5","outputId":"a06d9fb7-e806-4759-aac2-e185fac4c2c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py\u003e=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy\u003c2.0.0,\u003e=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c5.0.0dev,\u003e=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt\u003c1.15,\u003e=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n","Requirement already satisfied: tensorboard\u003c2.16,\u003e=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator\u003c2.16,\u003e=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras\u003c2.16,\u003e=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow) (0.42.0)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib\u003c2,\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (1.2.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (3.5.1)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (3.0.1)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (5.3.2)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (0.3.0)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib\u003c2,\u003e=0.5-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (2023.11.17)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1\u003c0.6.0,\u003e=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c2,\u003e=0.5-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow) (3.2.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"markdown","metadata":{"id":"Tgyf5Mr8tvVz"},"source":["train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112922,"status":"ok","timestamp":1701790672529,"user":{"displayName":"liu rongchuan","userId":"03500046369369319821"},"user_tz":-480},"id":"BeQH73gFs-6y","outputId":"fbf49455-37b7-4bd7-91dd-988122c14947"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-12-05 15:36:05.444941: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-05 15:36:05.445011: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-05 15:36:05.445052: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-05 15:36:05.455165: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-05 15:36:06.707755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","124 images were found in the dataset.\n","103 images for training.\n","21 images for validation.\n","['/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/11.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/12.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/13.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/14.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/15.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/16.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/19.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/2.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/20.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/21.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/22.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/25.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/29.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/3.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/31.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/35.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/36.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/37.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/38.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/39.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/4.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/40.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/6.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/7.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/1.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/12.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/13.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/17.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/18.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/19.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/2.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/21.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/22.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/23.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/24.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/25.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/26.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/29.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/3.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/4.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/5.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/6.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/7.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/9.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/1.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/10.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/11.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/12.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/13.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/14.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/16.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/17.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/18.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/21.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/26.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/27.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/3.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/30.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/4.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/5.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/6.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/7.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/8.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/9.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/10.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/11.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/14.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/15.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/18.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/2.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/20.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/21.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/22.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/23.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/24.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/26.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/27.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/28.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/3.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/4.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/5.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/6.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/8.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/9.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/13.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/14.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/15.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/18.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/19.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/2.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/20.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/22.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/24.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/25.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/26.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/27.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/28.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/29.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/30.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/4.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/7.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/8.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/9.jpg']\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n","['/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/26.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/27.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/5.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/8.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/black soil/9.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/10.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/20.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/27.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/cinder soil/28.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/20.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/23.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/24.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/laterite soil/29.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/16.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/19.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/29.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/peat soil/30.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/16.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/17.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/21.jpg', '/content/drive/MyDrive/城市工程系统智能化/Soil types train/yellow soil/5.jpg']\n","[0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]\n","Using 2 dataloader workers every process\n","_IncompatibleKeys(missing_keys=['classifier.fc.weight', 'classifier.fc.bias'], unexpected_keys=[])\n","[train epoch 0] loss: 1.585, acc: 0.330: 100% 13/13 [00:19\u003c00:00,  1.48s/it]\n","[valid epoch 0] loss: 1.542, acc: 0.476: 100% 3/3 [00:05\u003c00:00,  1.72s/it]\n","[train epoch 1] loss: 1.491, acc: 0.631: 100% 13/13 [00:13\u003c00:00,  1.07s/it]\n","[valid epoch 1] loss: 1.456, acc: 0.667: 100% 3/3 [00:01\u003c00:00,  2.17it/s]\n","[train epoch 2] loss: 1.386, acc: 0.738: 100% 13/13 [00:14\u003c00:00,  1.10s/it]\n","[valid epoch 2] loss: 1.328, acc: 0.619: 100% 3/3 [00:01\u003c00:00,  2.79it/s]\n","[train epoch 3] loss: 1.250, acc: 0.699: 100% 13/13 [00:14\u003c00:00,  1.13s/it]\n","[valid epoch 3] loss: 1.173, acc: 0.667: 100% 3/3 [00:01\u003c00:00,  2.76it/s]\n","[train epoch 4] loss: 1.189, acc: 0.689: 100% 13/13 [00:14\u003c00:00,  1.14s/it]\n","[valid epoch 4] loss: 0.987, acc: 0.619: 100% 3/3 [00:01\u003c00:00,  2.82it/s]\n"]}],"source":["!python \"/content/drive/MyDrive/城市工程系统智能化/MobileViT/train.py\""]},{"cell_type":"markdown","metadata":{"id":"vtA1UhfW3rF6"},"source":["test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQwQoRTQ3qiq"},"outputs":[],"source":["!python '/content/drive/MyDrive/城市工程系统智能化/MobileViT/test.py'"]},{"cell_type":"markdown","metadata":{"id":"WNOTuS-VnUYd"},"source":["attention assisted augmentation training\n","基于注意力机制的数据增强策略\n","\n","对每个子文件夹按顺序抽取30%进行训练，然后在测试集上进行测试，或者也抽取30%进行测试。分别得到该模型在各个类上的损失（多尝试几种），对损失求softmax，根据得到的值对数据进行数据增强（从增强数据文件夹中抽取%数量的数据进行训练），值越大数据增强得到的数据越多。\n","对每个子文件夹抽取30%的数据进行训练，对剩下的数据进行数据增强，对剩下的数据加上增强的数据取一半再次进行训练，然后对剩下的一半数据增强。\n","\n","1、将一个文件夹中各个子文件夹中的图片划分为90%的训练集和10%的测试集。其中，每个子文件夹中是不同种类的数据，文件名是对应的种类名\n","2、抽取各个子文件夹的训练集中33%的数据进行训练\n","3、在各个子文件夹测试集上进行测试，得到损失，求softmax=?%\n","4、在各个子文件夹的增强数据集中取出?%×30%的数据和剩下训练集的一半进行训练\n","5、在各个子文件夹测试集上进行测试，得到损失，求softmax=?%\n","6、在各个子文件夹剩余的增强数据集中取出?%×30%的数据和剩下的训练集进行训练\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"executionInfo":{"elapsed":8497,"status":"error","timestamp":1704633496823,"user":{"displayName":"liu rongchuan","userId":"03500046369369319821"},"user_tz":-480},"id":"jShVrLV8cniw","outputId":"dd35b3e7-607e-4bae-ec62-da84d5d03e8a"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-2-f4c4418e84af\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 107\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# 数据加载\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 112\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_split_1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--\u003e 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -\u003e None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--\u003e 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 42\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in train_split_1."]}],"source":["import os\n","import shutil\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","\n","# 设置随机种子以保证结果的可重复性\n","random.seed(42)\n","torch.manual_seed(42)\n","\n","# 定义LSTM模型（示例模型）\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(LSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        out, _ = self.lstm(x)\n","        out = self.fc(out[:, -1, :])  # 取最后一个时间步的输出\n","        return out\n","\n","# 数据集路径\n","# 创建文件夹\n","for i in range(1, 4):\n","    split_train_folder = f\"train_split_{i}\"\n","    os.makedirs(split_train_folder, exist_ok=True)\n","\n","os.makedirs(\"test\", exist_ok=True)\n","\n","dataset_path = \"/content/drive/MyDrive/城市工程系统智能化/Soil types\"\n","num_classes = 5\n","\n","# 划分训练集和测试集\n","def split_dataset(dataset_path, train_ratio=0.8):\n","    classes = os.listdir(dataset_path)\n","    train_dir = \"train\"\n","    test_dir = \"test\"\n","\n","    for cls in classes:\n","        cls_path = os.path.join(dataset_path, cls)\n","        images = os.listdir(cls_path)\n","        random.shuffle(images)\n","\n","        train_size = int(len(images) * train_ratio)\n","        train_images = images[:train_size]\n","        test_images = images[train_size:]\n","\n","        # 创建训练集和测试集文件夹\n","        train_cls_path = os.path.join(train_dir, cls)\n","        test_cls_path = os.path.join(test_dir, cls)\n","\n","        os.makedirs(train_cls_path, exist_ok=True)\n","        os.makedirs(test_cls_path, exist_ok=True)\n","\n","        # 将图像拷贝到相应文件夹\n","        for img in train_images:\n","            shutil.copy(os.path.join(cls_path, img), os.path.join(train_cls_path, img))\n","        for img in test_images:\n","            shutil.copy(os.path.join(cls_path, img), os.path.join(test_cls_path, img))\n","\n","# 划分训练集为三个子集\n","def split_train_dataset(train_path, ratios=[0.4, 0.3, 0.3]):\n","    classes = os.listdir(train_path)\n","\n","    for cls in classes:\n","        cls_path = os.path.join(train_path, cls)\n","        images = os.listdir(cls_path)\n","        random.shuffle(images)\n","\n","        sizes = [int(ratio * len(images)) for ratio in ratios]\n","        splits = [images[:sizes[0]], images[sizes[0]:sizes[0] + sizes[1]], images[sizes[0] + sizes[1]:]]\n","\n","        # 创建三个子集文件夹\n","        for i, split in enumerate(splits):\n","            split_cls_path = os.path.join(f\"train_split_{i + 1}\", cls)\n","            os.makedirs(split_cls_path, exist_ok=True)\n","\n","            # 将图像拷贝到相应文件夹\n","            for img in split:\n","                shutil.copy(os.path.join(cls_path, img), os.path.join(split_cls_path, img))\n","\n","# 定义数据增强和转换\n","transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","])\n","\n","# 设置超参数\n","input_size = 224\n","hidden_size = 128\n","num_layers = 2\n","learning_rate = 0.001\n","epochs = 10\n","\n","# 初始化LSTM模型和损失函数\n","model = LSTMModel(input_size, hidden_size, num_layers, num_classes)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 训练模型\n","for epoch in range(epochs):\n","    # 第一个拆分的训练集\n","    split_train_dataset(\"train_split_1\")\n","\n","    # 数据加载\n","    train_dataset = ImageFolder(\"train_split_1\", transform=transform)\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","    for batch in train_loader:\n","        inputs, labels = batch\n","\n","        # 模型训练\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # 测试集测试\n","    test_dataset = ImageFolder(\"test\", transform=transform)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n","\n","    class_losses = {i: 0.0 for i in range(num_classes)}\n","    class_counts = {i: 0 for i in range(num_classes)}\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            inputs, labels = batch\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            for i in range(num_classes):\n","                mask = labels == i\n","                class_losses[i] += torch.sum(loss[mask]).item()\n","                class_counts[i] += mask.sum().item()\n","\n","    # 计算各个类别的损失值\n","    for i in range(num_classes):\n","        class_losses[i] /= class_counts[i]\n","\n","    # 求softmax得到各个类别的增强比\n","    exp_losses = torch.exp(torch.tensor(list(class_losses.values())))\n","    enhancement_ratios = exp_losses / exp_losses.sum()\n","\n","    # 对第二个划分的训练集进行数据增强\n","    split_train_dataset(\"train_split_2\", ratios=enhancement_ratios.tolist())\n","\n","    # 数据加载\n","    train_dataset = ImageFolder(\"train_split_2\", transform=transform)\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","    for batch in train_loader:\n","        inputs, labels = batch\n","\n","        # 模型训练\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # 对第三个训练集进行数据增强\n","    split_train_dataset(\"train_split_3\", ratios=enhancement_ratios.tolist())\n","\n","    # 数据加载\n","    train_dataset = ImageFolder(\"train_split_3\", transform=transform)\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","    for batch in train_loader:\n","        inputs, labels = batch\n","\n","        # 模型训练\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # 使用全部测试集测试\n","    test_dataset = ImageFolder(\"test\", transform=transform)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n","\n","    class_losses = {i: 0.0 for i in range(num_classes)}\n","    class_counts = {i: 0 for i in range(num_classes)}\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            inputs, labels = batch\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            for i in range(num_classes):\n","                mask = labels == i\n","                class_losses[i] += torch.sum(loss[mask]).item()\n","                class_counts[i] += mask.sum().item()\n","\n","    # 计算各个类别的损失值\n","    for i in range(num_classes):\n","        class_losses[i] /= class_counts[i]\n","\n","    print(f\"Epoch {epoch + 1}/{epochs} completed\")\n","\n","# 训练结束后保存模型\n","torch.save(model.state_dict(), \"lstm_model.pth\")\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":44721,"status":"ok","timestamp":1704686562961,"user":{"displayName":"liu rongchuan","userId":"03500046369369319821"},"user_tz":-480},"id":"8W8Yfjo6Pj1S"},"outputs":[],"source":["#这段代码得到的数据集不正宗\n","import os\n","import shutil\n","import random\n","\n","def split_dataset(dataset_path, save_path, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n","    # 获取所有类别文件夹\n","    classes = [folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))]\n","\n","    for class_folder in classes:\n","        class_path = os.path.join(dataset_path, class_folder)\n","        images = [img for img in os.listdir(class_path) if img.endswith('.jpg') or img.endswith('.png')]\n","        random.shuffle(images)\n","\n","        total_images = len(images)\n","        train_size = int(total_images * train_ratio)\n","        val_size = int(total_images * val_ratio)\n","        test_size = total_images - train_size - val_size\n","\n","        # 创建保存路径\n","        save_train_path = os.path.join(save_path, 'train', class_folder)\n","        save_val_path = os.path.join(save_path, 'val', class_folder)\n","        save_test_path = os.path.join(save_path, 'test', class_folder)\n","\n","        os.makedirs(save_train_path, exist_ok=True)\n","        os.makedirs(save_val_path, exist_ok=True)\n","        os.makedirs(save_test_path, exist_ok=True)\n","\n","        # 划分训练集\n","        train_set = images[:train_size]\n","        for img in train_set:\n","            shutil.copy(os.path.join(class_path, img), os.path.join(save_train_path, img))\n","        # 分别创建三个子文件夹\n","        #train_set1_path = os.path.join(save_train_path, 'train_set1')\n","        #train_set2_path = os.path.join(save_train_path, 'train_set2')\n","        #train_set3_path = os.path.join(save_train_path, 'train_set3')\n","\n","        #os.makedirs(train_set1_path, exist_ok=True)\n","        #os.makedirs(train_set2_path, exist_ok=True)\n","        #os.makedirs(train_set3_path, exist_ok=True)\n","\n","        # 将数据均匀分配到三个子文件夹中\n","        #for i, img in enumerate(train_set):\n","         #   if i % 3 == 0:\n","          #      shutil.copy(os.path.join(class_path, img), os.path.join(train_set1_path, img))\n","           # elif i % 3 == 1:\n","            #    shutil.copy(os.path.join(class_path, img), os.path.join(train_set2_path, img))\n","            #else:\n","             #   shutil.copy(os.path.join(class_path, img), os.path.join(train_set3_path, img))\n","\n","        # 划分验证集\n","        val_set = images[train_size:train_size + val_size]\n","        for img in val_set:\n","            shutil.copy(os.path.join(class_path, img), os.path.join(save_val_path, img))\n","\n","        # 划分测试集\n","        test_set = images[train_size + val_size:]\n","        for img in test_set:\n","            shutil.copy(os.path.join(class_path, img), os.path.join(save_test_path, img))\n","\n","# 用法示例\n","dataset_path = '/content/drive/MyDrive/城市工程系统智能化/Soil types'\n","save_path = '/content/drive/MyDrive/城市工程系统智能化/attention_augmented'\n","split_dataset(dataset_path, save_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EfvTuww8mCJV"},"outputs":[],"source":["##这个代码得到的attention_augmented1是最正规的数据集\n","import os\n","import shutil\n","import random\n","\n","def split_dataset(dataset_path, save_path, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n","    # 获取所有类别文件夹\n","    classes = [folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))]\n","\n","    for class_folder in classes:\n","        class_path = os.path.join(dataset_path, class_folder)\n","        images = [img for img in os.listdir(class_path) if img.endswith('.jpg') or img.endswith('.png')]\n","        random.shuffle(images)\n","\n","        total_images = len(images)\n","        train_size = int(total_images * train_ratio)\n","        val_size = int(total_images * val_ratio)\n","        test_size = total_images - train_size - val_size\n","\n","        # 创建保存路径\n","        save_train_path = os.path.join(save_path, 'train')\n","        save_val_path = os.path.join(save_path, 'val', class_folder)\n","        save_test_path = os.path.join(save_path, 'test', class_folder)\n","\n","        os.makedirs(save_train_path, exist_ok=True)\n","        os.makedirs(save_val_path, exist_ok=True)\n","        os.makedirs(save_test_path, exist_ok=True)\n","\n","        # 划分训练集\n","        train_set = images[:train_size]\n","\n","        # 分别创建三个子文件夹\n","        train_set1_path = os.path.join(save_train_path, 'train_set1', class_folder)\n","        train_set2_path = os.path.join(save_train_path, 'train_set2', class_folder)\n","        train_set3_path = os.path.join(save_train_path, 'train_set3', class_folder)\n","\n","        os.makedirs(train_set1_path, exist_ok=True)\n","        os.makedirs(train_set2_path, exist_ok=True)\n","        os.makedirs(train_set3_path, exist_ok=True)\n","\n","        # 将数据均匀分配到三个子文件夹中\n","        for i, img in enumerate(train_set):\n","            if i % 3 == 0:\n","                shutil.copy(os.path.join(class_path, img), os.path.join(train_set1_path, img))\n","            elif i % 3 == 1:\n","                shutil.copy(os.path.join(class_path, img), os.path.join(train_set2_path, img))\n","            else:\n","                shutil.copy(os.path.join(class_path, img), os.path.join(train_set3_path, img))\n","\n","        # 划分验证集\n","        val_set = images[train_size:train_size + val_size]\n","        for img in val_set:\n","            shutil.copy(os.path.join(class_path, img), os.path.join(save_val_path, img))\n","\n","        # 划分测试集\n","        test_set = images[train_size + val_size:]\n","        for img in test_set:\n","            shutil.copy(os.path.join(class_path, img), os.path.join(save_test_path, img))\n","\n","# 用法示例\n","dataset_path = '/content/drive/MyDrive/城市工程系统智能化/Soil types'\n","save_path = '/content/drive/MyDrive/城市工程系统智能化/attention_augmented1'\n","split_dataset(dataset_path, save_path)\n"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":110413,"status":"ok","timestamp":1704706898359,"user":{"displayName":"liu rongchuan","userId":"03500046369369319821"},"user_tz":-480},"id":"G9I8v-aWXtms","outputId":"6aab9f05-2176-4581-dc5d-2e72adac0b38"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Epoch: 0 [0/124 (0%)]\tLoss: 1.608904\n","\n","Test set: Average loss: 1.6041, Accuracy: 0.23\n","\n","Validation Accuracy after Epoch 1: 0.23\n","Train Epoch: 1 [0/124 (0%)]\tLoss: 1.598004\n","\n","Test set: Average loss: 1.5982, Accuracy: 0.23\n","\n","Validation Accuracy after Epoch 2: 0.23\n","Train Epoch: 2 [0/124 (0%)]\tLoss: 1.599200\n","\n","Test set: Average loss: 1.5915, Accuracy: 0.23\n","\n","Validation Accuracy after Epoch 3: 0.23\n","Train Epoch: 3 [0/124 (0%)]\tLoss: 1.578173\n","\n","Test set: Average loss: 1.5855, Accuracy: 0.23\n","\n","Validation Accuracy after Epoch 4: 0.23\n","Train Epoch: 4 [0/124 (0%)]\tLoss: 1.567704\n","\n","Test set: Average loss: 1.5793, Accuracy: 0.23\n","\n","Validation Accuracy after Epoch 5: 0.23\n","Train Epoch: 5 [0/124 (0%)]\tLoss: 1.570063\n","\n","Test set: Average loss: 1.5722, Accuracy: 0.31\n","\n","Validation Accuracy after Epoch 6: 0.31\n","Train Epoch: 6 [0/124 (0%)]\tLoss: 1.555111\n","\n","Test set: Average loss: 1.5644, Accuracy: 0.35\n","\n","Validation Accuracy after Epoch 7: 0.35\n","Train Epoch: 7 [0/124 (0%)]\tLoss: 1.539087\n","\n","Test set: Average loss: 1.5561, Accuracy: 0.38\n","\n","Validation Accuracy after Epoch 8: 0.38\n","Train Epoch: 8 [0/124 (0%)]\tLoss: 1.528482\n","\n","Test set: Average loss: 1.5443, Accuracy: 0.38\n","\n","Validation Accuracy after Epoch 9: 0.38\n","Train Epoch: 9 [0/124 (0%)]\tLoss: 1.527321\n","\n","Test set: Average loss: 1.5311, Accuracy: 0.38\n","\n","Validation Accuracy after Epoch 10: 0.38\n","Train Epoch: 10 [0/124 (0%)]\tLoss: 1.477666\n","\n","Test set: Average loss: 1.5145, Accuracy: 0.54\n","\n","Validation Accuracy after Epoch 11: 0.54\n","Train Epoch: 11 [0/124 (0%)]\tLoss: 1.473328\n","\n","Test set: Average loss: 1.4889, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 12: 0.58\n","Train Epoch: 12 [0/124 (0%)]\tLoss: 1.433715\n","\n","Test set: Average loss: 1.4543, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 13: 0.58\n","Train Epoch: 13 [0/124 (0%)]\tLoss: 1.389949\n","\n","Test set: Average loss: 1.4116, Accuracy: 0.50\n","\n","Validation Accuracy after Epoch 14: 0.50\n","Train Epoch: 14 [0/124 (0%)]\tLoss: 1.339897\n","\n","Test set: Average loss: 1.3682, Accuracy: 0.46\n","\n","Validation Accuracy after Epoch 15: 0.46\n","Train Epoch: 15 [0/124 (0%)]\tLoss: 1.276943\n","\n","Test set: Average loss: 1.3146, Accuracy: 0.54\n","\n","Validation Accuracy after Epoch 16: 0.54\n","Train Epoch: 16 [0/124 (0%)]\tLoss: 1.138062\n","\n","Test set: Average loss: 1.2715, Accuracy: 0.54\n","\n","Validation Accuracy after Epoch 17: 0.54\n","Train Epoch: 17 [0/124 (0%)]\tLoss: 1.169397\n","\n","Test set: Average loss: 1.0909, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 18: 0.69\n","Train Epoch: 18 [0/124 (0%)]\tLoss: 1.092572\n","\n","Test set: Average loss: 1.0897, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 19: 0.65\n","Train Epoch: 19 [0/124 (0%)]\tLoss: 1.047915\n","\n","Test set: Average loss: 1.0181, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 20: 0.69\n","Train Epoch: 20 [0/124 (0%)]\tLoss: 0.894665\n","\n","Test set: Average loss: 0.9656, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 21: 0.73\n","Train Epoch: 21 [0/124 (0%)]\tLoss: 0.934432\n","\n","Test set: Average loss: 0.9335, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 22: 0.69\n","Train Epoch: 22 [0/124 (0%)]\tLoss: 0.847738\n","\n","Test set: Average loss: 0.9127, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 23: 0.69\n","Train Epoch: 23 [0/124 (0%)]\tLoss: 0.768675\n","\n","Test set: Average loss: 0.8898, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 24: 0.69\n","Train Epoch: 24 [0/124 (0%)]\tLoss: 0.757239\n","\n","Test set: Average loss: 1.1150, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 25: 0.62\n","Train Epoch: 25 [0/124 (0%)]\tLoss: 0.915941\n","\n","Test set: Average loss: 1.0217, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 26: 0.62\n","Train Epoch: 26 [0/124 (0%)]\tLoss: 0.954880\n","\n","Test set: Average loss: 0.9065, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 27: 0.69\n","Train Epoch: 27 [0/124 (0%)]\tLoss: 0.670397\n","\n","Test set: Average loss: 0.8273, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 28: 0.73\n","Train Epoch: 28 [0/124 (0%)]\tLoss: 0.809895\n","\n","Test set: Average loss: 0.8286, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 29: 0.73\n","Train Epoch: 29 [0/124 (0%)]\tLoss: 0.820953\n","\n","Test set: Average loss: 0.8567, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 30: 0.65\n","Train Epoch: 30 [0/124 (0%)]\tLoss: 0.730707\n","\n","Test set: Average loss: 0.9763, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 31: 0.62\n","Train Epoch: 31 [0/124 (0%)]\tLoss: 0.620502\n","\n","Test set: Average loss: 0.9710, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 32: 0.62\n","Train Epoch: 32 [0/124 (0%)]\tLoss: 0.659797\n","\n","Test set: Average loss: 0.7323, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 33: 0.73\n","Train Epoch: 33 [0/124 (0%)]\tLoss: 0.608331\n","\n","Test set: Average loss: 0.7963, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 34: 0.69\n","Train Epoch: 34 [0/124 (0%)]\tLoss: 0.632413\n","\n","Test set: Average loss: 0.9145, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 35: 0.65\n","Train Epoch: 35 [0/124 (0%)]\tLoss: 0.545183\n","\n","Test set: Average loss: 0.9018, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 36: 0.65\n","Train Epoch: 36 [0/124 (0%)]\tLoss: 0.695093\n","\n","Test set: Average loss: 0.9627, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 37: 0.58\n","Train Epoch: 37 [0/124 (0%)]\tLoss: 0.639018\n","\n","Test set: Average loss: 0.8540, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 38: 0.65\n","Train Epoch: 38 [0/124 (0%)]\tLoss: 0.599762\n","\n","Test set: Average loss: 0.9122, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 39: 0.62\n","Train Epoch: 39 [0/124 (0%)]\tLoss: 0.764723\n","\n","Test set: Average loss: 0.9723, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 40: 0.58\n","Train Epoch: 40 [0/124 (0%)]\tLoss: 0.915129\n","\n","Test set: Average loss: 0.9094, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 41: 0.62\n","Train Epoch: 41 [0/124 (0%)]\tLoss: 0.918282\n","\n","Test set: Average loss: 1.0001, Accuracy: 0.50\n","\n","Validation Accuracy after Epoch 42: 0.50\n","Train Epoch: 42 [0/124 (0%)]\tLoss: 0.951930\n","\n","Test set: Average loss: 0.9337, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 43: 0.58\n","Train Epoch: 43 [0/124 (0%)]\tLoss: 0.919298\n","\n","Test set: Average loss: 0.9403, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 44: 0.58\n","Train Epoch: 44 [0/124 (0%)]\tLoss: 0.973915\n","\n","Test set: Average loss: 0.9391, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 45: 0.58\n","Train Epoch: 45 [0/124 (0%)]\tLoss: 0.940068\n","\n","Test set: Average loss: 0.9309, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 46: 0.58\n","Train Epoch: 46 [0/124 (0%)]\tLoss: 1.060247\n","\n","Test set: Average loss: 0.9203, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 47: 0.58\n","Train Epoch: 47 [0/124 (0%)]\tLoss: 0.923170\n","\n","Test set: Average loss: 0.9808, Accuracy: 0.50\n","\n","Validation Accuracy after Epoch 48: 0.50\n","Train Epoch: 48 [0/124 (0%)]\tLoss: 0.877887\n","\n","Test set: Average loss: 0.9420, Accuracy: 0.54\n","\n","Validation Accuracy after Epoch 49: 0.54\n","Train Epoch: 49 [0/124 (0%)]\tLoss: 0.974898\n","\n","Test set: Average loss: 0.9224, Accuracy: 0.54\n","\n","Validation Accuracy after Epoch 50: 0.54\n","Train Epoch: 50 [0/124 (0%)]\tLoss: 0.882333\n","\n","Test set: Average loss: 0.9436, Accuracy: 0.50\n","\n","Validation Accuracy after Epoch 51: 0.50\n","Train Epoch: 51 [0/124 (0%)]\tLoss: 0.846352\n","\n","Test set: Average loss: 0.8561, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 52: 0.69\n","Train Epoch: 52 [0/124 (0%)]\tLoss: 0.833465\n","\n","Test set: Average loss: 0.9707, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 53: 0.58\n","Train Epoch: 53 [0/124 (0%)]\tLoss: 1.069913\n","\n","Test set: Average loss: 0.9976, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 54: 0.58\n","Train Epoch: 54 [0/124 (0%)]\tLoss: 1.010582\n","\n","Test set: Average loss: 0.9886, Accuracy: 0.54\n","\n","Validation Accuracy after Epoch 55: 0.54\n","Train Epoch: 55 [0/124 (0%)]\tLoss: 0.974244\n","\n","Test set: Average loss: 0.9653, Accuracy: 0.50\n","\n","Validation Accuracy after Epoch 56: 0.50\n","Train Epoch: 56 [0/124 (0%)]\tLoss: 0.949688\n","\n","Test set: Average loss: 0.9372, Accuracy: 0.50\n","\n","Validation Accuracy after Epoch 57: 0.50\n","Train Epoch: 57 [0/124 (0%)]\tLoss: 0.889038\n","\n","Test set: Average loss: 0.9101, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 58: 0.58\n","Train Epoch: 58 [0/124 (0%)]\tLoss: 0.845013\n","\n","Test set: Average loss: 0.8913, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 59: 0.58\n","Train Epoch: 59 [0/124 (0%)]\tLoss: 0.827775\n","\n","Test set: Average loss: 0.8813, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 60: 0.65\n","Train Epoch: 60 [0/124 (0%)]\tLoss: 0.805905\n","\n","Test set: Average loss: 0.8807, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 61: 0.65\n","Train Epoch: 61 [0/124 (0%)]\tLoss: 0.803213\n","\n","Test set: Average loss: 1.5371, Accuracy: 0.35\n","\n","Validation Accuracy after Epoch 62: 0.35\n","Train Epoch: 62 [0/124 (0%)]\tLoss: 1.142174\n","\n","Test set: Average loss: 2.0874, Accuracy: 0.19\n","\n","Validation Accuracy after Epoch 63: 0.19\n","Train Epoch: 63 [0/124 (0%)]\tLoss: 1.857957\n","\n","Test set: Average loss: 2.0790, Accuracy: 0.19\n","\n","Validation Accuracy after Epoch 64: 0.19\n","Train Epoch: 64 [0/124 (0%)]\tLoss: 1.799009\n","\n","Test set: Average loss: 2.0197, Accuracy: 0.19\n","\n","Validation Accuracy after Epoch 65: 0.19\n","Train Epoch: 65 [0/124 (0%)]\tLoss: 2.017613\n","\n","Test set: Average loss: 1.9195, Accuracy: 0.19\n","\n","Validation Accuracy after Epoch 66: 0.19\n","Train Epoch: 66 [0/124 (0%)]\tLoss: 1.754092\n","\n","Test set: Average loss: 1.7980, Accuracy: 0.19\n","\n","Validation Accuracy after Epoch 67: 0.19\n","Train Epoch: 67 [0/124 (0%)]\tLoss: 1.733132\n","\n","Test set: Average loss: 1.6729, Accuracy: 0.27\n","\n","Validation Accuracy after Epoch 68: 0.27\n","Train Epoch: 68 [0/124 (0%)]\tLoss: 1.575778\n","\n","Test set: Average loss: 1.5599, Accuracy: 0.35\n","\n","Validation Accuracy after Epoch 69: 0.35\n","Train Epoch: 69 [0/124 (0%)]\tLoss: 1.440857\n","\n","Test set: Average loss: 1.4672, Accuracy: 0.35\n","\n","Validation Accuracy after Epoch 70: 0.35\n","Train Epoch: 70 [0/124 (0%)]\tLoss: 1.296991\n","\n","Test set: Average loss: 1.3931, Accuracy: 0.35\n","\n","Validation Accuracy after Epoch 71: 0.35\n","Train Epoch: 71 [0/124 (0%)]\tLoss: 1.336582\n","\n","Test set: Average loss: 1.3349, Accuracy: 0.38\n","\n","Validation Accuracy after Epoch 72: 0.38\n","Train Epoch: 72 [0/124 (0%)]\tLoss: 1.203951\n","\n","Test set: Average loss: 1.2885, Accuracy: 0.54\n","\n","Validation Accuracy after Epoch 73: 0.54\n","Train Epoch: 73 [0/124 (0%)]\tLoss: 1.165613\n","\n","Test set: Average loss: 1.2094, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 74: 0.73\n","Train Epoch: 74 [0/124 (0%)]\tLoss: 1.130919\n","\n","Test set: Average loss: 1.1582, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 75: 0.62\n","Train Epoch: 75 [0/124 (0%)]\tLoss: 0.978535\n","\n","Test set: Average loss: 1.1644, Accuracy: 0.50\n","\n","Validation Accuracy after Epoch 76: 0.50\n","Train Epoch: 76 [0/124 (0%)]\tLoss: 1.014653\n","\n","Test set: Average loss: 1.1723, Accuracy: 0.46\n","\n","Validation Accuracy after Epoch 77: 0.46\n","Train Epoch: 77 [0/124 (0%)]\tLoss: 0.989976\n","\n","Test set: Average loss: 1.1647, Accuracy: 0.46\n","\n","Validation Accuracy after Epoch 78: 0.46\n","Train Epoch: 78 [0/124 (0%)]\tLoss: 1.022077\n","\n","Test set: Average loss: 1.1397, Accuracy: 0.46\n","\n","Validation Accuracy after Epoch 79: 0.46\n","Train Epoch: 79 [0/124 (0%)]\tLoss: 1.028610\n","\n","Test set: Average loss: 1.0986, Accuracy: 0.50\n","\n","Validation Accuracy after Epoch 80: 0.50\n","Train Epoch: 80 [0/124 (0%)]\tLoss: 0.982553\n","\n","Test set: Average loss: 1.0493, Accuracy: 0.50\n","\n","Validation Accuracy after Epoch 81: 0.50\n","Train Epoch: 81 [0/124 (0%)]\tLoss: 0.994816\n","\n","Test set: Average loss: 0.9998, Accuracy: 0.54\n","\n","Validation Accuracy after Epoch 82: 0.54\n","Train Epoch: 82 [0/124 (0%)]\tLoss: 0.855887\n","\n","Test set: Average loss: 0.9590, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 83: 0.65\n","Train Epoch: 83 [0/124 (0%)]\tLoss: 0.771208\n","\n","Test set: Average loss: 0.9296, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 84: 0.65\n","Train Epoch: 84 [0/124 (0%)]\tLoss: 0.834466\n","\n","Test set: Average loss: 0.9096, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 85: 0.65\n","Train Epoch: 85 [0/124 (0%)]\tLoss: 0.768762\n","\n","Test set: Average loss: 0.8942, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 86: 0.65\n","Train Epoch: 86 [0/124 (0%)]\tLoss: 0.760406\n","\n","Test set: Average loss: 0.8851, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 87: 0.62\n","Train Epoch: 87 [0/124 (0%)]\tLoss: 0.760592\n","\n","Test set: Average loss: 0.8804, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 88: 0.62\n","Train Epoch: 88 [0/124 (0%)]\tLoss: 0.710929\n","\n","Test set: Average loss: 0.8781, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 89: 0.62\n","Train Epoch: 89 [0/124 (0%)]\tLoss: 0.727417\n","\n","Test set: Average loss: 0.8749, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 90: 0.62\n","Train Epoch: 90 [0/124 (0%)]\tLoss: 0.627065\n","\n","Test set: Average loss: 0.8704, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 91: 0.62\n","Train Epoch: 91 [0/124 (0%)]\tLoss: 0.616953\n","\n","Test set: Average loss: 0.8644, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 92: 0.62\n","Train Epoch: 92 [0/124 (0%)]\tLoss: 0.678229\n","\n","Test set: Average loss: 0.8542, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 93: 0.65\n","Train Epoch: 93 [0/124 (0%)]\tLoss: 0.719661\n","\n","Test set: Average loss: 0.8430, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 94: 0.69\n","Train Epoch: 94 [0/124 (0%)]\tLoss: 0.687508\n","\n","Test set: Average loss: 0.8336, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 95: 0.69\n","Train Epoch: 95 [0/124 (0%)]\tLoss: 0.661533\n","\n","Test set: Average loss: 0.8269, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 96: 0.69\n","Train Epoch: 96 [0/124 (0%)]\tLoss: 0.620575\n","\n","Test set: Average loss: 0.8223, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 97: 0.69\n","Train Epoch: 97 [0/124 (0%)]\tLoss: 0.605728\n","\n","Test set: Average loss: 0.8200, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 98: 0.69\n","Train Epoch: 98 [0/124 (0%)]\tLoss: 0.565665\n","\n","Test set: Average loss: 0.8180, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 99: 0.69\n","Train Epoch: 99 [0/124 (0%)]\tLoss: 0.627936\n","\n","Test set: Average loss: 0.8156, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 100: 0.69\n","Train Epoch: 100 [0/124 (0%)]\tLoss: 0.549853\n","\n","Test set: Average loss: 0.8148, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 101: 0.69\n","Train Epoch: 101 [0/124 (0%)]\tLoss: 0.615862\n","\n","Test set: Average loss: 0.8110, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 102: 0.69\n","Train Epoch: 102 [0/124 (0%)]\tLoss: 0.567161\n","\n","Test set: Average loss: 0.8055, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 103: 0.69\n","Train Epoch: 103 [0/124 (0%)]\tLoss: 0.427133\n","\n","Test set: Average loss: 0.8101, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 104: 0.69\n","Train Epoch: 104 [0/124 (0%)]\tLoss: 0.658051\n","\n","Test set: Average loss: 0.8064, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 105: 0.69\n","Train Epoch: 105 [0/124 (0%)]\tLoss: 0.617959\n","\n","Test set: Average loss: 0.7752, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 106: 0.73\n","Train Epoch: 106 [0/124 (0%)]\tLoss: 0.473661\n","\n","Test set: Average loss: 0.8258, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 107: 0.69\n","Train Epoch: 107 [0/124 (0%)]\tLoss: 0.497684\n","\n","Test set: Average loss: 0.7918, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 108: 0.69\n","Train Epoch: 108 [0/124 (0%)]\tLoss: 0.514489\n","\n","Test set: Average loss: 0.8057, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 109: 0.69\n","Train Epoch: 109 [0/124 (0%)]\tLoss: 0.653560\n","\n","Test set: Average loss: 0.8065, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 110: 0.69\n","Train Epoch: 110 [0/124 (0%)]\tLoss: 0.619150\n","\n","Test set: Average loss: 0.8343, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 111: 0.69\n","Train Epoch: 111 [0/124 (0%)]\tLoss: 0.506661\n","\n","Test set: Average loss: 0.8391, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 112: 0.73\n","Train Epoch: 112 [0/124 (0%)]\tLoss: 0.571618\n","\n","Test set: Average loss: 0.8122, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 113: 0.73\n","Train Epoch: 113 [0/124 (0%)]\tLoss: 0.587815\n","\n","Test set: Average loss: 0.8143, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 114: 0.73\n","Train Epoch: 114 [0/124 (0%)]\tLoss: 0.619555\n","\n","Test set: Average loss: 0.8155, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 115: 0.73\n","Train Epoch: 115 [0/124 (0%)]\tLoss: 0.722919\n","\n","Test set: Average loss: 0.8116, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 116: 0.73\n","Train Epoch: 116 [0/124 (0%)]\tLoss: 0.566631\n","\n","Test set: Average loss: 0.8527, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 117: 0.73\n","Train Epoch: 117 [0/124 (0%)]\tLoss: 0.504060\n","\n","Test set: Average loss: 0.8857, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 118: 0.73\n","Train Epoch: 118 [0/124 (0%)]\tLoss: 0.556770\n","\n","Test set: Average loss: 0.8006, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 119: 0.77\n","Train Epoch: 119 [0/124 (0%)]\tLoss: 0.468344\n","\n","Test set: Average loss: 0.8122, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 120: 0.73\n","Train Epoch: 120 [0/124 (0%)]\tLoss: 0.591114\n","\n","Test set: Average loss: 0.8103, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 121: 0.73\n","Train Epoch: 121 [0/124 (0%)]\tLoss: 0.559218\n","\n","Test set: Average loss: 0.8117, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 122: 0.73\n","Train Epoch: 122 [0/124 (0%)]\tLoss: 0.486916\n","\n","Test set: Average loss: 0.8583, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 123: 0.73\n","Train Epoch: 123 [0/124 (0%)]\tLoss: 0.586155\n","\n","Test set: Average loss: 0.8447, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 124: 0.73\n","Train Epoch: 124 [0/124 (0%)]\tLoss: 0.473811\n","\n","Test set: Average loss: 0.8341, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 125: 0.73\n","Train Epoch: 125 [0/124 (0%)]\tLoss: 0.521573\n","\n","Test set: Average loss: 0.7879, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 126: 0.77\n","Train Epoch: 126 [0/124 (0%)]\tLoss: 0.444998\n","\n","Test set: Average loss: 0.7814, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 127: 0.77\n","Train Epoch: 127 [0/124 (0%)]\tLoss: 0.671112\n","\n","Test set: Average loss: 0.7914, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 128: 0.77\n","Train Epoch: 128 [0/124 (0%)]\tLoss: 0.533740\n","\n","Test set: Average loss: 0.8203, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 129: 0.77\n","Train Epoch: 129 [0/124 (0%)]\tLoss: 0.534840\n","\n","Test set: Average loss: 0.7683, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 130: 0.77\n","Train Epoch: 130 [0/124 (0%)]\tLoss: 0.431524\n","\n","Test set: Average loss: 0.7494, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 131: 0.77\n","Train Epoch: 131 [0/124 (0%)]\tLoss: 0.491976\n","\n","Test set: Average loss: 0.7368, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 132: 0.77\n","Train Epoch: 132 [0/124 (0%)]\tLoss: 0.501717\n","\n","Test set: Average loss: 0.7873, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 133: 0.77\n","Train Epoch: 133 [0/124 (0%)]\tLoss: 0.496789\n","\n","Test set: Average loss: 0.7613, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 134: 0.81\n","Train Epoch: 134 [0/124 (0%)]\tLoss: 0.402443\n","\n","Test set: Average loss: 0.7713, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 135: 0.77\n","Train Epoch: 135 [0/124 (0%)]\tLoss: 0.463485\n","\n","Test set: Average loss: 0.7522, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 136: 0.77\n","Train Epoch: 136 [0/124 (0%)]\tLoss: 0.511632\n","\n","Test set: Average loss: 0.7449, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 137: 0.81\n","Train Epoch: 137 [0/124 (0%)]\tLoss: 0.450251\n","\n","Test set: Average loss: 0.7095, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 138: 0.85\n","Train Epoch: 138 [0/124 (0%)]\tLoss: 0.446171\n","\n","Test set: Average loss: 0.7460, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 139: 0.81\n","Train Epoch: 139 [0/124 (0%)]\tLoss: 0.363483\n","\n","Test set: Average loss: 0.7317, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 140: 0.85\n","Train Epoch: 140 [0/124 (0%)]\tLoss: 0.431506\n","\n","Test set: Average loss: 0.7703, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 141: 0.81\n","Train Epoch: 141 [0/124 (0%)]\tLoss: 0.473850\n","\n","Test set: Average loss: 0.7129, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 142: 0.81\n","Train Epoch: 142 [0/124 (0%)]\tLoss: 0.386234\n","\n","Test set: Average loss: 0.7429, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 143: 0.73\n","Train Epoch: 143 [0/124 (0%)]\tLoss: 0.414016\n","\n","Test set: Average loss: 0.6971, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 144: 0.81\n","Train Epoch: 144 [0/124 (0%)]\tLoss: 0.374505\n","\n","Test set: Average loss: 0.7235, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 145: 0.77\n","Train Epoch: 145 [0/124 (0%)]\tLoss: 0.485895\n","\n","Test set: Average loss: 0.7001, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 146: 0.73\n","Train Epoch: 146 [0/124 (0%)]\tLoss: 0.394694\n","\n","Test set: Average loss: 0.7785, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 147: 0.69\n","Train Epoch: 147 [0/124 (0%)]\tLoss: 0.505217\n","\n","Test set: Average loss: 0.8046, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 148: 0.69\n","Train Epoch: 148 [0/124 (0%)]\tLoss: 0.414059\n","\n","Test set: Average loss: 0.7701, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 149: 0.73\n","Train Epoch: 149 [0/124 (0%)]\tLoss: 0.428117\n","\n","Test set: Average loss: 0.8488, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 150: 0.81\n","Train Epoch: 150 [0/124 (0%)]\tLoss: 0.555558\n","\n","Test set: Average loss: 0.7674, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 151: 0.77\n","Train Epoch: 151 [0/124 (0%)]\tLoss: 0.355375\n","\n","Test set: Average loss: 0.7481, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 152: 0.81\n","Train Epoch: 152 [0/124 (0%)]\tLoss: 0.394418\n","\n","Test set: Average loss: 0.7289, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 153: 0.85\n","Train Epoch: 153 [0/124 (0%)]\tLoss: 0.434121\n","\n","Test set: Average loss: 0.7782, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 154: 0.85\n","Train Epoch: 154 [0/124 (0%)]\tLoss: 0.537036\n","\n","Test set: Average loss: 0.7344, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 155: 0.81\n","Train Epoch: 155 [0/124 (0%)]\tLoss: 0.397916\n","\n","Test set: Average loss: 0.7510, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 156: 0.77\n","Train Epoch: 156 [0/124 (0%)]\tLoss: 0.461358\n","\n","Test set: Average loss: 0.7830, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 157: 0.81\n","Train Epoch: 157 [0/124 (0%)]\tLoss: 0.425490\n","\n","Test set: Average loss: 0.8543, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 158: 0.77\n","Train Epoch: 158 [0/124 (0%)]\tLoss: 0.427992\n","\n","Test set: Average loss: 0.8116, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 159: 0.73\n","Train Epoch: 159 [0/124 (0%)]\tLoss: 0.412946\n","\n","Test set: Average loss: 0.8419, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 160: 0.69\n","Train Epoch: 160 [0/124 (0%)]\tLoss: 0.384915\n","\n","Test set: Average loss: 0.8926, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 161: 0.65\n","Train Epoch: 161 [0/124 (0%)]\tLoss: 0.360112\n","\n","Test set: Average loss: 0.8832, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 162: 0.73\n","Train Epoch: 162 [0/124 (0%)]\tLoss: 0.406349\n","\n","Test set: Average loss: 0.8305, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 163: 0.77\n","Train Epoch: 163 [0/124 (0%)]\tLoss: 0.322869\n","\n","Test set: Average loss: 0.7998, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 164: 0.77\n","Train Epoch: 164 [0/124 (0%)]\tLoss: 0.347945\n","\n","Test set: Average loss: 0.7725, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 165: 0.85\n","Train Epoch: 165 [0/124 (0%)]\tLoss: 0.338197\n","\n","Test set: Average loss: 0.7667, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 166: 0.81\n","Train Epoch: 166 [0/124 (0%)]\tLoss: 0.305431\n","\n","Test set: Average loss: 0.7563, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 167: 0.85\n","Train Epoch: 167 [0/124 (0%)]\tLoss: 0.348834\n","\n","Test set: Average loss: 0.7907, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 168: 0.85\n","Train Epoch: 168 [0/124 (0%)]\tLoss: 0.378343\n","\n","Test set: Average loss: 0.7622, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 169: 0.85\n","Train Epoch: 169 [0/124 (0%)]\tLoss: 0.335210\n","\n","Test set: Average loss: 0.8391, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 170: 0.77\n","Train Epoch: 170 [0/124 (0%)]\tLoss: 0.419139\n","\n","Test set: Average loss: 0.8173, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 171: 0.73\n","Train Epoch: 171 [0/124 (0%)]\tLoss: 0.342197\n","\n","Test set: Average loss: 0.7090, Accuracy: 0.88\n","\n","Validation Accuracy after Epoch 172: 0.88\n","Train Epoch: 172 [0/124 (0%)]\tLoss: 0.364661\n","\n","Test set: Average loss: 0.8437, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 173: 0.77\n","Train Epoch: 173 [0/124 (0%)]\tLoss: 0.548259\n","\n","Test set: Average loss: 0.8102, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 174: 0.77\n","Train Epoch: 174 [0/124 (0%)]\tLoss: 0.373012\n","\n","Test set: Average loss: 0.7882, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 175: 0.85\n","Train Epoch: 175 [0/124 (0%)]\tLoss: 0.301716\n","\n","Test set: Average loss: 0.7645, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 176: 0.77\n","Train Epoch: 176 [0/124 (0%)]\tLoss: 0.243835\n","\n","Test set: Average loss: 0.7758, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 177: 0.73\n","Train Epoch: 177 [0/124 (0%)]\tLoss: 0.333960\n","\n","Test set: Average loss: 0.7704, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 178: 0.77\n","Train Epoch: 178 [0/124 (0%)]\tLoss: 0.314679\n","\n","Test set: Average loss: 0.8037, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 179: 0.81\n","Train Epoch: 179 [0/124 (0%)]\tLoss: 0.320094\n","\n","Test set: Average loss: 0.8135, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 180: 0.85\n","Train Epoch: 180 [0/124 (0%)]\tLoss: 0.313619\n","\n","Test set: Average loss: 0.7118, Accuracy: 0.88\n","\n","Validation Accuracy after Epoch 181: 0.88\n","Train Epoch: 181 [0/124 (0%)]\tLoss: 0.339929\n","\n","Test set: Average loss: 0.7409, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 182: 0.69\n","Train Epoch: 182 [0/124 (0%)]\tLoss: 0.337335\n","\n","Test set: Average loss: 0.5758, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 183: 0.81\n","Train Epoch: 183 [0/124 (0%)]\tLoss: 0.341438\n","\n","Test set: Average loss: 0.5614, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 184: 0.85\n","Train Epoch: 184 [0/124 (0%)]\tLoss: 0.340928\n","\n","Test set: Average loss: 0.5663, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 185: 0.81\n","Train Epoch: 185 [0/124 (0%)]\tLoss: 0.346632\n","\n","Test set: Average loss: 0.6048, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 186: 0.77\n","Train Epoch: 186 [0/124 (0%)]\tLoss: 0.294188\n","\n","Test set: Average loss: 0.6642, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 187: 0.77\n","Train Epoch: 187 [0/124 (0%)]\tLoss: 0.341562\n","\n","Test set: Average loss: 0.7093, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 188: 0.81\n","Train Epoch: 188 [0/124 (0%)]\tLoss: 0.255629\n","\n","Test set: Average loss: 0.6664, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 189: 0.85\n","Train Epoch: 189 [0/124 (0%)]\tLoss: 0.284862\n","\n","Test set: Average loss: 0.7952, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 190: 0.85\n","Train Epoch: 190 [0/124 (0%)]\tLoss: 0.366116\n","\n","Test set: Average loss: 0.8713, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 191: 0.81\n","Train Epoch: 191 [0/124 (0%)]\tLoss: 0.325631\n","\n","Test set: Average loss: 0.8375, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 192: 0.85\n","Train Epoch: 192 [0/124 (0%)]\tLoss: 0.275998\n","\n","Test set: Average loss: 0.8310, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 193: 0.85\n","Train Epoch: 193 [0/124 (0%)]\tLoss: 0.310197\n","\n","Test set: Average loss: 0.8599, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 194: 0.85\n","Train Epoch: 194 [0/124 (0%)]\tLoss: 0.255504\n","\n","Test set: Average loss: 0.9064, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 195: 0.81\n","Train Epoch: 195 [0/124 (0%)]\tLoss: 0.324488\n","\n","Test set: Average loss: 0.8252, Accuracy: 0.88\n","\n","Validation Accuracy after Epoch 196: 0.88\n","Train Epoch: 196 [0/124 (0%)]\tLoss: 0.273085\n","\n","Test set: Average loss: 0.8235, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 197: 0.85\n","Train Epoch: 197 [0/124 (0%)]\tLoss: 0.345879\n","\n","Test set: Average loss: 0.8091, Accuracy: 0.88\n","\n","Validation Accuracy after Epoch 198: 0.88\n","Train Epoch: 198 [0/124 (0%)]\tLoss: 0.319757\n","\n","Test set: Average loss: 0.8080, Accuracy: 0.88\n","\n","Validation Accuracy after Epoch 199: 0.88\n","Train Epoch: 199 [0/124 (0%)]\tLoss: 0.234608\n","\n","Test set: Average loss: 0.8015, Accuracy: 0.88\n","\n","Validation Accuracy after Epoch 200: 0.88\n","\n","Test set: Average loss: 0.4579, Accuracy: 0.79\n","\n","Final Test Accuracy: 0.79\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nfor epoch in range(10):\\n    train(model, train_loader, criterion, optimizer, epoch, device)\\n\\n    # 在测试集每个子文件夹中随机选取30%的图像进行测试\\n    for test_set in ['test_set1', 'test_set2', 'test_set3']:\\n        test_subset = datasets.ImageFolder(root=os.path.join(dataset_path, 'test', test_set), transform=transform)\\n        test_subset_loader = DataLoader(test_subset, batch_size=64, shuffle=True)\\n\\n        subset_loss, subset_accuracy = test(model, test_subset_loader, device)\\n\\n        # 求得损失值的softmax作为增强比\\n        enhancement_ratios = softmax(torch.tensor(subset_loss), dim=0)\\n\\n        # 对第二个子训练集进行数据增强\\n        train_dataset2 = datasets.ImageFolder(root=os.path.join(dataset_path, f'train/{test_set}'), transform=transform)\\n        enhanced_train_dataset2 = data_augmentation(train_dataset2, enhancement_ratios)\\n\\n        # 更新训练数据集\\n        train_loader.dataset.data = enhanced_train_dataset2\\n\\n        # 继续训练\\n        train(model, train_loader, criterion, optimizer, epoch, device)\\n\\n# 在整个测试集上进行最终测试\\nfinal_test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\\nfinal_test_loss, final_test_accuracy = test(model, final_test_loader, device)\\n\\nprint(f'Final Test Accuracy: {final_test_accuracy:.2f}')\\n\""]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["#没有进行数据增强的训练\n","\n","'''\n","import os\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","from sklearn.metrics import accuracy_score\n","\n","# 数据集类\n","class CustomDataset(Dataset):\n","    def __init__(self, folder_path, transform=None):\n","        self.folder_path = folder_path\n","        self.classes = os.listdir(folder_path)\n","        self.samples = []\n","        for class_name in self.classes:\n","            class_path = os.path.join(folder_path, class_name)\n","            for sample_set in os.listdir(class_path):\n","                sample_set_path = os.path.join(class_path, sample_set)\n","                self.samples.extend([(os.path.join(sample_set_path, filename), int(class_name)) for filename in os.listdir(sample_set_path)])\n","\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        image_path, label = self.samples[idx]\n","        image = Image.open(image_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","# LSTM模型定义\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(LSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        _, (h_n, _) = self.lstm(x)\n","        out = self.fc(h_n[-1, :, :])\n","        return out\n","\n","# 训练模型\n","def train_model(train_loader, model, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    return running_loss / len(train_loader)\n","\n","# 测试模型\n","def test_model(test_loader, model, device):\n","    model.eval()\n","    all_labels = []\n","    all_outputs = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","\n","            all_labels.extend(labels.cpu().numpy())\n","            all_outputs.extend(predicted.cpu().numpy())\n","\n","    accuracy = accuracy_score(all_labels, all_outputs)\n","    return accuracy\n","\n","# 数据增强函数\n","def data_augmentation(data_path, enhancement_ratios):\n","    transform = transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n","        transforms.RandomRotation(30),\n","        transforms.ToTensor(),\n","    ])\n","\n","    enhanced_dataset = CustomDataset(data_path, transform=transform)\n","    return enhanced_dataset\n","\n","# 主训练循环\n","def train_loop(train_paths, val_path, test_path, num_epochs=10):\n","    input_size = 224\n","    hidden_size = 128\n","    num_classes = 5\n","    learning_rate = 0.001\n","    batch_size = 16\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model = LSTMModel(input_size, hidden_size, num_classes).to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    for epoch in range(num_epochs):\n","        # 数据增强函数\n","        enhancement_ratios = None\n","        if epoch \u003e 0:  # 不是第一个epoch才进行数据增强\n","            # 对第一个拆分的子训练集进行测试，获取各个类别的损失值\n","            train_loss_set1 = test_model(train_paths[0], model, criterion, device)\n","\n","            # 随机选取30%的图像数据进行测试\n","            sampled_indices = random.sample(range(len(train_loss_set1)), int(0.3 * len(train_loss_set1)))\n","            sampled_loss_set1 = [train_loss_set1[i] for i in sampled_indices]\n","\n","            # 对损失值求softmax得到各个类别的增强比\n","            softmax_probs = nn.functional.softmax(torch.tensor(sampled_loss_set1), dim=0)\n","            enhancement_ratios = softmax_probs.numpy()\n","\n","        for train_path in train_paths:\n","            # 对当前子训练集进行数据增强\n","            enhanced_train_set = data_augmentation(train_path, enhancement_ratios)\n","\n","            # 对增强后的子训练集进行模型训练\n","            enhanced_train_loader = DataLoader(enhanced_train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n","            train_model(enhanced_train_loader, model, criterion, optimizer, device)\n","\n","        # 训练模型\n","        train_loss = test_model(train_paths[0], model, criterion, device)\n","\n","        # 在验证集上测试模型\n","        val_accuracy = test_model(val_path, model, device)\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","        # 在测试集上测试模型\n","        test_accuracy = test_model(test_path, model, device)\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Test Accuracy: {test_accuracy:.4f}\")\n","\n","# 数据集文件夹路径\n","base_path = '/content/drive/MyDrive/城市工程系统智能化/attention_augmented'\n","train_paths = [os.path.join(base_path, 'train', class_name) for class_name in os.listdir(os.path.join(base_path, 'train'))]\n","val_path = os.path.join(base_path, 'val')\n","test_path = os.path.join(base_path, 'test')\n","\n","# 运行主训练循环\n","train_loop(train_paths, val_path, test_path, num_epochs=10)\n","'''\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.nn.functional import softmax\n","import random\n","import torch.nn.functional as F\n","import os\n","\n","# 设定种子以确保可重复性\n","torch.manual_seed(42)\n","random.seed(42)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 定义LSTM模型\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(LSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        # Reshape input to (batch_size, sequence_length, input_size)\n","        x = x.view(x.size(0), x.size(3), -1).permute(0, 2, 1)\n","\n","        out, _ = self.lstm(x)\n","        out = self.fc(out[:, -1, :])  # 取最后一个时间步的输出\n","        return out\n","\n","# 数据增强\n","def data_augmentation(data, enhancement_ratios):\n","    # 这里只是一个示例，你需要根据你的需求进行适当的数据增强操作\n","    augmented_data = data * enhancement_ratios.unsqueeze(0).unsqueeze(-1).expand_as(data)\n","    return augmented_data\n","\n","# 训练模型\n","def train(model, train_loader, criterion, optimizer, epoch, device):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 10 == 0:\n","            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n","                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n","\n","# 测试模型\n","def test(model, test_loader, device):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","\n","            output = model(data)\n","            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n","\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    accuracy = correct / len(test_loader.dataset)\n","    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}\\n')\n","\n","    return test_loss, accuracy\n","\n","# 数据集路径\n","dataset_path = '/content/drive/MyDrive/城市工程系统智能化/attention_augmented'\n","#不进行数据增强的数据集路径\n","#dataset_path = '/content/drive/MyDrive/城市工程系统智能化/attention_augmented'\n","# 定义转换\n","transform = transforms.Compose([transforms.Resize((32, 32)),\n","                                transforms.ToTensor()])\n","\n","# 创建数据集和数据加载器\n","#train_dataset = datasets.ImageFolder(root=os.path.join(dataset_path,'train', 'train_set1'), transform=transform)\n","train_dataset = datasets.ImageFolder(root=os.path.join(dataset_path,'train'), transform=transform)\n","val_dataset = datasets.ImageFolder(root=os.path.join(dataset_path,'val'), transform=transform)\n","test_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, 'test'), transform=transform)\n","\n","# 划分验证集\n","#validation_split = 0.1\n","#dataset_size = len(train_dataset)\n","#indices = list(range(dataset_size))\n","#split = int(validation_split * dataset_size)\n","\n","#train_indices, val_indices = indices[split:], indices[:split]\n","\n","#train_sampler = SubsetRandomSampler(train_indices)\n","#val_sampler = SubsetRandomSampler(val_indices)\n","\n","# 数据加载器\n","#train_loader = DataLoader(train_dataset, batch_size=64, sampler=train_sampler)\n","#val_loader = DataLoader(train_dataset, batch_size=64, sampler=val_sampler)\n","#test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n","\n","# 初始化模型、损失函数和优化器\n","input_size = 32  # 输入的大小，根据你的数据集调整\n","hidden_size = 64  # LSTM隐藏层的大小，根据需要调整\n","num_classes = 5  # 类别数，根据你的数据集调整\n","model = LSTMModel(input_size, hidden_size, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","test_dataset_path = os.path.join(dataset_path, 'test')\n","final_test_dataset = datasets.ImageFolder(root=test_dataset_path, transform=transform)\n","final_test_loader = DataLoader(final_test_dataset, batch_size=64, shuffle=True)\n","# 训练10个epoch\n","'''\n","for epoch in range(10):\n","    train(model, train_loader, criterion, optimizer, epoch, device)\n","\n","    # 在整个测试集上进行最终测试\n","    final_test_loss, final_test_accuracy = test(model, final_test_loader, device)\n","\n","    print(f'Final Test Accuracy: {final_test_accuracy:.2f}')\n","'''\n","for epoch in range(200):\n","    train(model, train_loader, criterion, optimizer, epoch, device)\n","\n","    # 在验证集上进行测试\n","    val_loss, val_accuracy = test(model, val_loader, device)\n","    print(f'Validation Accuracy after Epoch {epoch + 1}: {val_accuracy:.2f}')\n","\n","# 在整个测试集上进行最终测试\n","final_test_loss, final_test_accuracy = test(model, test_loader, device)\n","print(f'Final Test Accuracy: {final_test_accuracy:.2f}')\n","'''\n","for epoch in range(10):\n","    train(model, train_loader, criterion, optimizer, epoch, device)\n","\n","    # 在测试集每个子文件夹中随机选取30%的图像进行测试\n","    for test_set in ['test_set1', 'test_set2', 'test_set3']:\n","        test_subset = datasets.ImageFolder(root=os.path.join(dataset_path, 'test', test_set), transform=transform)\n","        test_subset_loader = DataLoader(test_subset, batch_size=64, shuffle=True)\n","\n","        subset_loss, subset_accuracy = test(model, test_subset_loader, device)\n","\n","        # 求得损失值的softmax作为增强比\n","        enhancement_ratios = softmax(torch.tensor(subset_loss), dim=0)\n","\n","        # 对第二个子训练集进行数据增强\n","        train_dataset2 = datasets.ImageFolder(root=os.path.join(dataset_path, f'train/{test_set}'), transform=transform)\n","        enhanced_train_dataset2 = data_augmentation(train_dataset2, enhancement_ratios)\n","\n","        # 更新训练数据集\n","        train_loader.dataset.data = enhanced_train_dataset2\n","\n","        # 继续训练\n","        train(model, train_loader, criterion, optimizer, epoch, device)\n","\n","# 在整个测试集上进行最终测试\n","final_test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n","final_test_loss, final_test_accuracy = test(model, final_test_loader, device)\n","\n","print(f'Final Test Accuracy: {final_test_accuracy:.2f}')\n","'''"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1065936,"status":"ok","timestamp":1704708268068,"user":{"displayName":"liu rongchuan","userId":"03500046369369319821"},"user_tz":-480},"id":"t1oTqg1S9ss_","outputId":"ba879395-39fa-44df-c3b6-4d9c509d0da1"},"outputs":[{"name":"stdout","output_type":"stream","text":["增强倍数 8.0\n","Train Epoch: 0 [0/992 (0%)]\tLoss: 1.600679\n","Train Epoch: 0 [640/992 (62%)]\tLoss: 1.577483\n","\n","Test set: Average loss: 1.5682, Accuracy: 0.27\n","\n","Validation Accuracy after Epoch 1: 0.27\n","增强倍数 8.0\n","Train Epoch: 1 [0/992 (0%)]\tLoss: 1.560701\n","Train Epoch: 1 [640/992 (62%)]\tLoss: 1.512272\n","\n","Test set: Average loss: 1.4396, Accuracy: 0.46\n","\n","Validation Accuracy after Epoch 2: 0.46\n","增强倍数 8.0\n","Train Epoch: 2 [0/992 (0%)]\tLoss: 1.385511\n","Train Epoch: 2 [640/992 (62%)]\tLoss: 1.186623\n","\n","Test set: Average loss: 1.0894, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 3: 0.62\n","增强倍数 8.0\n","Train Epoch: 3 [0/992 (0%)]\tLoss: 1.109602\n","Train Epoch: 3 [640/992 (62%)]\tLoss: 0.836405\n","\n","Test set: Average loss: 0.8516, Accuracy: 0.54\n","\n","Validation Accuracy after Epoch 4: 0.54\n","增强倍数 8.0\n","Train Epoch: 4 [0/992 (0%)]\tLoss: 0.897352\n","Train Epoch: 4 [640/992 (62%)]\tLoss: 0.761587\n","\n","Test set: Average loss: 0.7744, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 5: 0.73\n","增强倍数 8.0\n","Train Epoch: 5 [0/992 (0%)]\tLoss: 1.008406\n","Train Epoch: 5 [640/992 (62%)]\tLoss: 0.787755\n","\n","Test set: Average loss: 0.8368, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 6: 0.69\n","增强倍数 8.0\n","Train Epoch: 6 [0/992 (0%)]\tLoss: 1.088904\n","Train Epoch: 6 [640/992 (62%)]\tLoss: 0.723395\n","\n","Test set: Average loss: 0.7586, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 7: 0.65\n","增强倍数 8.0\n","Train Epoch: 7 [0/992 (0%)]\tLoss: 0.684387\n","Train Epoch: 7 [640/992 (62%)]\tLoss: 0.772989\n","\n","Test set: Average loss: 0.8944, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 8: 0.73\n","增强倍数 8.0\n","Train Epoch: 8 [0/992 (0%)]\tLoss: 0.794913\n","Train Epoch: 8 [640/992 (62%)]\tLoss: 0.871510\n","\n","Test set: Average loss: 0.9167, Accuracy: 0.46\n","\n","Validation Accuracy after Epoch 9: 0.46\n","增强倍数 8.0\n","Train Epoch: 9 [0/992 (0%)]\tLoss: 0.710833\n","Train Epoch: 9 [640/992 (62%)]\tLoss: 1.111752\n","\n","Test set: Average loss: 1.0494, Accuracy: 0.54\n","\n","Validation Accuracy after Epoch 10: 0.54\n","增强倍数 8.0\n","Train Epoch: 10 [0/992 (0%)]\tLoss: 0.877157\n","Train Epoch: 10 [640/992 (62%)]\tLoss: 0.981819\n","\n","Test set: Average loss: 1.0667, Accuracy: 0.58\n","\n","Validation Accuracy after Epoch 11: 0.58\n","增强倍数 8.0\n","Train Epoch: 11 [0/992 (0%)]\tLoss: 0.750613\n","Train Epoch: 11 [640/992 (62%)]\tLoss: 0.773964\n","\n","Test set: Average loss: 0.8540, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 12: 0.69\n","增强倍数 8.0\n","Train Epoch: 12 [0/992 (0%)]\tLoss: 0.781565\n","Train Epoch: 12 [640/992 (62%)]\tLoss: 0.769395\n","\n","Test set: Average loss: 0.8239, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 13: 0.65\n","增强倍数 8.0\n","Train Epoch: 13 [0/992 (0%)]\tLoss: 1.078165\n","Train Epoch: 13 [640/992 (62%)]\tLoss: 0.677894\n","\n","Test set: Average loss: 0.8372, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 14: 0.73\n","增强倍数 8.0\n","Train Epoch: 14 [0/992 (0%)]\tLoss: 0.665500\n","Train Epoch: 14 [640/992 (62%)]\tLoss: 0.700990\n","\n","Test set: Average loss: 0.8403, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 15: 0.65\n","增强倍数 8.0\n","Train Epoch: 15 [0/992 (0%)]\tLoss: 0.583514\n","Train Epoch: 15 [640/992 (62%)]\tLoss: 0.640168\n","\n","Test set: Average loss: 0.7396, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 16: 0.81\n","增强倍数 8.0\n","Train Epoch: 16 [0/992 (0%)]\tLoss: 0.794631\n","Train Epoch: 16 [640/992 (62%)]\tLoss: 0.714072\n","\n","Test set: Average loss: 0.8432, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 17: 0.65\n","增强倍数 8.0\n","Train Epoch: 17 [0/992 (0%)]\tLoss: 0.709018\n","Train Epoch: 17 [640/992 (62%)]\tLoss: 0.793465\n","\n","Test set: Average loss: 0.7670, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 18: 0.65\n","增强倍数 8.0\n","Train Epoch: 18 [0/992 (0%)]\tLoss: 0.668997\n","Train Epoch: 18 [640/992 (62%)]\tLoss: 0.632979\n","\n","Test set: Average loss: 0.7609, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 19: 0.69\n","增强倍数 8.0\n","Train Epoch: 19 [0/992 (0%)]\tLoss: 0.781579\n","Train Epoch: 19 [640/992 (62%)]\tLoss: 0.568853\n","\n","Test set: Average loss: 0.7730, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 20: 0.69\n","增强倍数 8.0\n","Train Epoch: 20 [0/992 (0%)]\tLoss: 0.645299\n","Train Epoch: 20 [640/992 (62%)]\tLoss: 0.558801\n","\n","Test set: Average loss: 0.7899, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 21: 0.69\n","增强倍数 8.0\n","Train Epoch: 21 [0/992 (0%)]\tLoss: 0.628501\n","Train Epoch: 21 [640/992 (62%)]\tLoss: 0.641110\n","\n","Test set: Average loss: 0.7532, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 22: 0.77\n","增强倍数 8.0\n","Train Epoch: 22 [0/992 (0%)]\tLoss: 0.683143\n","Train Epoch: 22 [640/992 (62%)]\tLoss: 0.608963\n","\n","Test set: Average loss: 0.8079, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 23: 0.69\n","增强倍数 8.0\n","Train Epoch: 23 [0/992 (0%)]\tLoss: 0.616871\n","Train Epoch: 23 [640/992 (62%)]\tLoss: 0.622089\n","\n","Test set: Average loss: 0.9748, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 24: 0.65\n","增强倍数 8.0\n","Train Epoch: 24 [0/992 (0%)]\tLoss: 0.568747\n","Train Epoch: 24 [640/992 (62%)]\tLoss: 0.745485\n","\n","Test set: Average loss: 1.0912, Accuracy: 0.54\n","\n","Validation Accuracy after Epoch 25: 0.54\n","增强倍数 8.0\n","Train Epoch: 25 [0/992 (0%)]\tLoss: 1.084788\n","Train Epoch: 25 [640/992 (62%)]\tLoss: 0.815626\n","\n","Test set: Average loss: 0.8695, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 26: 0.62\n","增强倍数 8.0\n","Train Epoch: 26 [0/992 (0%)]\tLoss: 0.856340\n","Train Epoch: 26 [640/992 (62%)]\tLoss: 0.790487\n","\n","Test set: Average loss: 0.8282, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 27: 0.69\n","增强倍数 8.0\n","Train Epoch: 27 [0/992 (0%)]\tLoss: 0.693302\n","Train Epoch: 27 [640/992 (62%)]\tLoss: 0.657497\n","\n","Test set: Average loss: 0.7689, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 28: 0.73\n","增强倍数 8.0\n","Train Epoch: 28 [0/992 (0%)]\tLoss: 0.641988\n","Train Epoch: 28 [640/992 (62%)]\tLoss: 0.631139\n","\n","Test set: Average loss: 0.7879, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 29: 0.69\n","增强倍数 8.0\n","Train Epoch: 29 [0/992 (0%)]\tLoss: 0.583303\n","Train Epoch: 29 [640/992 (62%)]\tLoss: 0.553356\n","\n","Test set: Average loss: 0.8246, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 30: 0.65\n","增强倍数 8.0\n","Train Epoch: 30 [0/992 (0%)]\tLoss: 0.468241\n","Train Epoch: 30 [640/992 (62%)]\tLoss: 0.484838\n","\n","Test set: Average loss: 0.7356, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 31: 0.81\n","增强倍数 8.0\n","Train Epoch: 31 [0/992 (0%)]\tLoss: 0.528700\n","Train Epoch: 31 [640/992 (62%)]\tLoss: 0.565669\n","\n","Test set: Average loss: 0.7603, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 32: 0.81\n","增强倍数 8.0\n","Train Epoch: 32 [0/992 (0%)]\tLoss: 0.505060\n","Train Epoch: 32 [640/992 (62%)]\tLoss: 0.530002\n","\n","Test set: Average loss: 0.8668, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 33: 0.73\n","增强倍数 8.0\n","Train Epoch: 33 [0/992 (0%)]\tLoss: 0.413988\n","Train Epoch: 33 [640/992 (62%)]\tLoss: 0.559627\n","\n","Test set: Average loss: 0.7603, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 34: 0.73\n","增强倍数 8.0\n","Train Epoch: 34 [0/992 (0%)]\tLoss: 0.501629\n","Train Epoch: 34 [640/992 (62%)]\tLoss: 1.052811\n","\n","Test set: Average loss: 1.5798, Accuracy: 0.35\n","\n","Validation Accuracy after Epoch 35: 0.35\n","增强倍数 8.0\n","Train Epoch: 35 [0/992 (0%)]\tLoss: 1.011638\n","Train Epoch: 35 [640/992 (62%)]\tLoss: 0.660839\n","\n","Test set: Average loss: 0.9082, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 36: 0.65\n","增强倍数 8.0\n","Train Epoch: 36 [0/992 (0%)]\tLoss: 0.582742\n","Train Epoch: 36 [640/992 (62%)]\tLoss: 0.575757\n","\n","Test set: Average loss: 0.8355, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 37: 0.77\n","增强倍数 8.0\n","Train Epoch: 37 [0/992 (0%)]\tLoss: 0.505402\n","Train Epoch: 37 [640/992 (62%)]\tLoss: 0.598477\n","\n","Test set: Average loss: 0.8835, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 38: 0.65\n","增强倍数 8.0\n","Train Epoch: 38 [0/992 (0%)]\tLoss: 0.495036\n","Train Epoch: 38 [640/992 (62%)]\tLoss: 0.384979\n","\n","Test set: Average loss: 0.7954, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 39: 0.81\n","增强倍数 8.0\n","Train Epoch: 39 [0/992 (0%)]\tLoss: 0.533251\n","Train Epoch: 39 [640/992 (62%)]\tLoss: 0.497747\n","\n","Test set: Average loss: 0.7743, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 40: 0.77\n","增强倍数 8.0\n","Train Epoch: 40 [0/992 (0%)]\tLoss: 0.521657\n","Train Epoch: 40 [640/992 (62%)]\tLoss: 0.514971\n","\n","Test set: Average loss: 0.8630, Accuracy: 0.85\n","\n","Validation Accuracy after Epoch 41: 0.85\n","增强倍数 8.0\n","Train Epoch: 41 [0/992 (0%)]\tLoss: 0.553230\n","Train Epoch: 41 [640/992 (62%)]\tLoss: 0.579676\n","\n","Test set: Average loss: 0.7128, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 42: 0.73\n","增强倍数 8.0\n","Train Epoch: 42 [0/992 (0%)]\tLoss: 0.665360\n","Train Epoch: 42 [640/992 (62%)]\tLoss: 0.505472\n","\n","Test set: Average loss: 0.9268, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 43: 0.73\n","增强倍数 8.0\n","Train Epoch: 43 [0/992 (0%)]\tLoss: 0.789556\n","Train Epoch: 43 [640/992 (62%)]\tLoss: 0.505638\n","\n","Test set: Average loss: 0.8373, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 44: 0.77\n","增强倍数 8.0\n","Train Epoch: 44 [0/992 (0%)]\tLoss: 0.568705\n","Train Epoch: 44 [640/992 (62%)]\tLoss: 0.516685\n","\n","Test set: Average loss: 0.6986, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 45: 0.77\n","增强倍数 8.0\n","Train Epoch: 45 [0/992 (0%)]\tLoss: 0.590729\n","Train Epoch: 45 [640/992 (62%)]\tLoss: 0.356371\n","\n","Test set: Average loss: 0.8518, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 46: 0.73\n","增强倍数 8.0\n","Train Epoch: 46 [0/992 (0%)]\tLoss: 0.553583\n","Train Epoch: 46 [640/992 (62%)]\tLoss: 0.542151\n","\n","Test set: Average loss: 0.8679, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 47: 0.81\n","增强倍数 8.0\n","Train Epoch: 47 [0/992 (0%)]\tLoss: 0.343546\n","Train Epoch: 47 [640/992 (62%)]\tLoss: 0.428686\n","\n","Test set: Average loss: 0.7540, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 48: 0.77\n","增强倍数 8.0\n","Train Epoch: 48 [0/992 (0%)]\tLoss: 0.387581\n","Train Epoch: 48 [640/992 (62%)]\tLoss: 0.502215\n","\n","Test set: Average loss: 0.9050, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 49: 0.69\n","增强倍数 8.0\n","Train Epoch: 49 [0/992 (0%)]\tLoss: 0.470146\n","Train Epoch: 49 [640/992 (62%)]\tLoss: 0.560315\n","\n","Test set: Average loss: 0.8510, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 50: 0.81\n","增强倍数 8.0\n","Train Epoch: 50 [0/992 (0%)]\tLoss: 0.522748\n","Train Epoch: 50 [640/992 (62%)]\tLoss: 0.422005\n","\n","Test set: Average loss: 0.9448, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 51: 0.69\n","增强倍数 8.0\n","Train Epoch: 51 [0/992 (0%)]\tLoss: 0.434823\n","Train Epoch: 51 [640/992 (62%)]\tLoss: 0.516983\n","\n","Test set: Average loss: 0.7943, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 52: 0.73\n","增强倍数 8.0\n","Train Epoch: 52 [0/992 (0%)]\tLoss: 0.464855\n","Train Epoch: 52 [640/992 (62%)]\tLoss: 0.339208\n","\n","Test set: Average loss: 0.8756, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 53: 0.73\n","增强倍数 8.0\n","Train Epoch: 53 [0/992 (0%)]\tLoss: 0.377606\n","Train Epoch: 53 [640/992 (62%)]\tLoss: 0.341262\n","\n","Test set: Average loss: 0.9427, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 54: 0.73\n","增强倍数 8.0\n","Train Epoch: 54 [0/992 (0%)]\tLoss: 0.554263\n","Train Epoch: 54 [640/992 (62%)]\tLoss: 0.421292\n","\n","Test set: Average loss: 0.6744, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 55: 0.77\n","增强倍数 8.0\n","Train Epoch: 55 [0/992 (0%)]\tLoss: 0.462838\n","Train Epoch: 55 [640/992 (62%)]\tLoss: 0.483013\n","\n","Test set: Average loss: 0.7960, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 56: 0.81\n","增强倍数 8.0\n","Train Epoch: 56 [0/992 (0%)]\tLoss: 0.525519\n","Train Epoch: 56 [640/992 (62%)]\tLoss: 0.386877\n","\n","Test set: Average loss: 0.8355, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 57: 0.77\n","增强倍数 8.0\n","Train Epoch: 57 [0/992 (0%)]\tLoss: 0.360027\n","Train Epoch: 57 [640/992 (62%)]\tLoss: 0.427907\n","\n","Test set: Average loss: 0.8651, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 58: 0.81\n","增强倍数 8.0\n","Train Epoch: 58 [0/992 (0%)]\tLoss: 0.436401\n","Train Epoch: 58 [640/992 (62%)]\tLoss: 0.378352\n","\n","Test set: Average loss: 0.8453, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 59: 0.77\n","增强倍数 8.0\n","Train Epoch: 59 [0/992 (0%)]\tLoss: 0.437738\n","Train Epoch: 59 [640/992 (62%)]\tLoss: 0.437534\n","\n","Test set: Average loss: 0.9986, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 60: 0.73\n","增强倍数 8.0\n","Train Epoch: 60 [0/992 (0%)]\tLoss: 0.746262\n","Train Epoch: 60 [640/992 (62%)]\tLoss: 0.472112\n","\n","Test set: Average loss: 0.7415, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 61: 0.69\n","增强倍数 8.0\n","Train Epoch: 61 [0/992 (0%)]\tLoss: 0.426064\n","Train Epoch: 61 [640/992 (62%)]\tLoss: 0.619442\n","\n","Test set: Average loss: 0.7762, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 62: 0.81\n","增强倍数 8.0\n","Train Epoch: 62 [0/992 (0%)]\tLoss: 0.494090\n","Train Epoch: 62 [640/992 (62%)]\tLoss: 0.492127\n","\n","Test set: Average loss: 0.8943, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 63: 0.77\n","增强倍数 8.0\n","Train Epoch: 63 [0/992 (0%)]\tLoss: 0.405004\n","Train Epoch: 63 [640/992 (62%)]\tLoss: 0.427631\n","\n","Test set: Average loss: 0.8794, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 64: 0.69\n","增强倍数 8.0\n","Train Epoch: 64 [0/992 (0%)]\tLoss: 0.578456\n","Train Epoch: 64 [640/992 (62%)]\tLoss: 0.357090\n","\n","Test set: Average loss: 0.7890, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 65: 0.73\n","增强倍数 8.0\n","Train Epoch: 65 [0/992 (0%)]\tLoss: 0.513311\n","Train Epoch: 65 [640/992 (62%)]\tLoss: 0.415949\n","\n","Test set: Average loss: 0.8654, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 66: 0.77\n","增强倍数 8.0\n","Train Epoch: 66 [0/992 (0%)]\tLoss: 0.426576\n","Train Epoch: 66 [640/992 (62%)]\tLoss: 0.461418\n","\n","Test set: Average loss: 0.7859, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 67: 0.69\n","增强倍数 8.0\n","Train Epoch: 67 [0/992 (0%)]\tLoss: 0.454935\n","Train Epoch: 67 [640/992 (62%)]\tLoss: 0.409139\n","\n","Test set: Average loss: 0.7759, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 68: 0.77\n","增强倍数 8.0\n","Train Epoch: 68 [0/992 (0%)]\tLoss: 0.337279\n","Train Epoch: 68 [640/992 (62%)]\tLoss: 0.380575\n","\n","Test set: Average loss: 0.8145, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 69: 0.77\n","增强倍数 8.0\n","Train Epoch: 69 [0/992 (0%)]\tLoss: 0.338550\n","Train Epoch: 69 [640/992 (62%)]\tLoss: 0.614543\n","\n","Test set: Average loss: 0.7681, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 70: 0.81\n","增强倍数 8.0\n","Train Epoch: 70 [0/992 (0%)]\tLoss: 0.387198\n","Train Epoch: 70 [640/992 (62%)]\tLoss: 0.237605\n","\n","Test set: Average loss: 0.8728, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 71: 0.65\n","增强倍数 8.0\n","Train Epoch: 71 [0/992 (0%)]\tLoss: 0.382125\n","Train Epoch: 71 [640/992 (62%)]\tLoss: 0.435826\n","\n","Test set: Average loss: 0.9103, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 72: 0.69\n","增强倍数 8.0\n","Train Epoch: 72 [0/992 (0%)]\tLoss: 0.337978\n","Train Epoch: 72 [640/992 (62%)]\tLoss: 0.294377\n","\n","Test set: Average loss: 0.9067, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 73: 0.69\n","增强倍数 8.0\n","Train Epoch: 73 [0/992 (0%)]\tLoss: 0.370570\n","Train Epoch: 73 [640/992 (62%)]\tLoss: 0.373803\n","\n","Test set: Average loss: 0.9318, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 74: 0.69\n","增强倍数 8.0\n","Train Epoch: 74 [0/992 (0%)]\tLoss: 0.255940\n","Train Epoch: 74 [640/992 (62%)]\tLoss: 0.275295\n","\n","Test set: Average loss: 0.9086, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 75: 0.73\n","增强倍数 8.0\n","Train Epoch: 75 [0/992 (0%)]\tLoss: 0.450465\n","Train Epoch: 75 [640/992 (62%)]\tLoss: 0.281312\n","\n","Test set: Average loss: 0.8256, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 76: 0.77\n","增强倍数 8.0\n","Train Epoch: 76 [0/992 (0%)]\tLoss: 0.256047\n","Train Epoch: 76 [640/992 (62%)]\tLoss: 0.397685\n","\n","Test set: Average loss: 0.7990, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 77: 0.69\n","增强倍数 8.0\n","Train Epoch: 77 [0/992 (0%)]\tLoss: 0.370001\n","Train Epoch: 77 [640/992 (62%)]\tLoss: 0.333823\n","\n","Test set: Average loss: 0.8057, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 78: 0.69\n","增强倍数 8.0\n","Train Epoch: 78 [0/992 (0%)]\tLoss: 0.418240\n","Train Epoch: 78 [640/992 (62%)]\tLoss: 0.522590\n","\n","Test set: Average loss: 0.8662, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 79: 0.77\n","增强倍数 8.0\n","Train Epoch: 79 [0/992 (0%)]\tLoss: 0.596098\n","Train Epoch: 79 [640/992 (62%)]\tLoss: 0.340344\n","\n","Test set: Average loss: 0.8428, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 80: 0.77\n","增强倍数 8.0\n","Train Epoch: 80 [0/992 (0%)]\tLoss: 0.679311\n","Train Epoch: 80 [640/992 (62%)]\tLoss: 0.421520\n","\n","Test set: Average loss: 0.7706, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 81: 0.69\n","增强倍数 8.0\n","Train Epoch: 81 [0/992 (0%)]\tLoss: 0.346120\n","Train Epoch: 81 [640/992 (62%)]\tLoss: 0.389432\n","\n","Test set: Average loss: 0.8926, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 82: 0.69\n","增强倍数 8.0\n","Train Epoch: 82 [0/992 (0%)]\tLoss: 0.343918\n","Train Epoch: 82 [640/992 (62%)]\tLoss: 0.405101\n","\n","Test set: Average loss: 0.9095, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 83: 0.73\n","增强倍数 8.0\n","Train Epoch: 83 [0/992 (0%)]\tLoss: 0.449371\n","Train Epoch: 83 [640/992 (62%)]\tLoss: 0.409823\n","\n","Test set: Average loss: 0.8705, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 84: 0.73\n","增强倍数 8.0\n","Train Epoch: 84 [0/992 (0%)]\tLoss: 0.262801\n","Train Epoch: 84 [640/992 (62%)]\tLoss: 0.395530\n","\n","Test set: Average loss: 0.9527, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 85: 0.65\n","增强倍数 8.0\n","Train Epoch: 85 [0/992 (0%)]\tLoss: 0.290104\n","Train Epoch: 85 [640/992 (62%)]\tLoss: 0.358237\n","\n","Test set: Average loss: 0.8250, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 86: 0.73\n","增强倍数 8.0\n","Train Epoch: 86 [0/992 (0%)]\tLoss: 0.351056\n","Train Epoch: 86 [640/992 (62%)]\tLoss: 0.357615\n","\n","Test set: Average loss: 0.8093, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 87: 0.73\n","增强倍数 8.0\n","Train Epoch: 87 [0/992 (0%)]\tLoss: 0.223208\n","Train Epoch: 87 [640/992 (62%)]\tLoss: 0.289022\n","\n","Test set: Average loss: 0.8784, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 88: 0.77\n","增强倍数 8.0\n","Train Epoch: 88 [0/992 (0%)]\tLoss: 0.263222\n","Train Epoch: 88 [640/992 (62%)]\tLoss: 0.282783\n","\n","Test set: Average loss: 0.7515, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 89: 0.69\n","增强倍数 8.0\n","Train Epoch: 89 [0/992 (0%)]\tLoss: 0.258439\n","Train Epoch: 89 [640/992 (62%)]\tLoss: 0.470624\n","\n","Test set: Average loss: 0.9083, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 90: 0.73\n","增强倍数 8.0\n","Train Epoch: 90 [0/992 (0%)]\tLoss: 0.219157\n","Train Epoch: 90 [640/992 (62%)]\tLoss: 0.353127\n","\n","Test set: Average loss: 0.9812, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 91: 0.73\n","增强倍数 8.0\n","Train Epoch: 91 [0/992 (0%)]\tLoss: 0.441126\n","Train Epoch: 91 [640/992 (62%)]\tLoss: 0.349393\n","\n","Test set: Average loss: 1.1588, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 92: 0.73\n","增强倍数 8.0\n","Train Epoch: 92 [0/992 (0%)]\tLoss: 0.267356\n","Train Epoch: 92 [640/992 (62%)]\tLoss: 0.326393\n","\n","Test set: Average loss: 1.0632, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 93: 0.73\n","增强倍数 8.0\n","Train Epoch: 93 [0/992 (0%)]\tLoss: 0.364660\n","Train Epoch: 93 [640/992 (62%)]\tLoss: 0.281868\n","\n","Test set: Average loss: 1.0863, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 94: 0.73\n","增强倍数 8.0\n","Train Epoch: 94 [0/992 (0%)]\tLoss: 0.251435\n","Train Epoch: 94 [640/992 (62%)]\tLoss: 0.294565\n","\n","Test set: Average loss: 1.0969, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 95: 0.69\n","增强倍数 8.0\n","Train Epoch: 95 [0/992 (0%)]\tLoss: 0.276939\n","Train Epoch: 95 [640/992 (62%)]\tLoss: 0.265052\n","\n","Test set: Average loss: 1.0384, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 96: 0.65\n","增强倍数 8.0\n","Train Epoch: 96 [0/992 (0%)]\tLoss: 0.248109\n","Train Epoch: 96 [640/992 (62%)]\tLoss: 0.243046\n","\n","Test set: Average loss: 1.0524, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 97: 0.73\n","增强倍数 8.0\n","Train Epoch: 97 [0/992 (0%)]\tLoss: 0.335656\n","Train Epoch: 97 [640/992 (62%)]\tLoss: 0.455643\n","\n","Test set: Average loss: 0.8361, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 98: 0.73\n","增强倍数 8.0\n","Train Epoch: 98 [0/992 (0%)]\tLoss: 0.294122\n","Train Epoch: 98 [640/992 (62%)]\tLoss: 0.492758\n","\n","Test set: Average loss: 1.0772, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 99: 0.65\n","增强倍数 8.0\n","Train Epoch: 99 [0/992 (0%)]\tLoss: 0.311175\n","Train Epoch: 99 [640/992 (62%)]\tLoss: 0.291724\n","\n","Test set: Average loss: 1.0073, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 100: 0.69\n","增强倍数 8.0\n","Train Epoch: 100 [0/992 (0%)]\tLoss: 0.322663\n","Train Epoch: 100 [640/992 (62%)]\tLoss: 0.359352\n","\n","Test set: Average loss: 0.9415, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 101: 0.73\n","增强倍数 8.0\n","Train Epoch: 101 [0/992 (0%)]\tLoss: 0.248353\n","Train Epoch: 101 [640/992 (62%)]\tLoss: 0.241968\n","\n","Test set: Average loss: 1.0506, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 102: 0.77\n","增强倍数 8.0\n","Train Epoch: 102 [0/992 (0%)]\tLoss: 0.333755\n","Train Epoch: 102 [640/992 (62%)]\tLoss: 0.243705\n","\n","Test set: Average loss: 0.9941, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 103: 0.73\n","增强倍数 8.0\n","Train Epoch: 103 [0/992 (0%)]\tLoss: 0.385405\n","Train Epoch: 103 [640/992 (62%)]\tLoss: 0.265835\n","\n","Test set: Average loss: 0.9084, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 104: 0.73\n","增强倍数 8.0\n","Train Epoch: 104 [0/992 (0%)]\tLoss: 0.478853\n","Train Epoch: 104 [640/992 (62%)]\tLoss: 0.302521\n","\n","Test set: Average loss: 1.1105, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 105: 0.62\n","增强倍数 8.0\n","Train Epoch: 105 [0/992 (0%)]\tLoss: 0.455655\n","Train Epoch: 105 [640/992 (62%)]\tLoss: 0.661452\n","\n","Test set: Average loss: 0.9358, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 106: 0.69\n","增强倍数 8.0\n","Train Epoch: 106 [0/992 (0%)]\tLoss: 0.433142\n","Train Epoch: 106 [640/992 (62%)]\tLoss: 0.455747\n","\n","Test set: Average loss: 1.0876, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 107: 0.69\n","增强倍数 8.0\n","Train Epoch: 107 [0/992 (0%)]\tLoss: 0.452482\n","Train Epoch: 107 [640/992 (62%)]\tLoss: 0.481613\n","\n","Test set: Average loss: 1.1136, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 108: 0.69\n","增强倍数 8.0\n","Train Epoch: 108 [0/992 (0%)]\tLoss: 0.316295\n","Train Epoch: 108 [640/992 (62%)]\tLoss: 0.332954\n","\n","Test set: Average loss: 0.9644, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 109: 0.69\n","增强倍数 8.0\n","Train Epoch: 109 [0/992 (0%)]\tLoss: 0.193209\n","Train Epoch: 109 [640/992 (62%)]\tLoss: 0.249779\n","\n","Test set: Average loss: 1.1440, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 110: 0.73\n","增强倍数 8.0\n","Train Epoch: 110 [0/992 (0%)]\tLoss: 0.589882\n","Train Epoch: 110 [640/992 (62%)]\tLoss: 0.310072\n","\n","Test set: Average loss: 0.9642, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 111: 0.73\n","增强倍数 8.0\n","Train Epoch: 111 [0/992 (0%)]\tLoss: 0.422259\n","Train Epoch: 111 [640/992 (62%)]\tLoss: 0.662316\n","\n","Test set: Average loss: 0.9303, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 112: 0.73\n","增强倍数 8.0\n","Train Epoch: 112 [0/992 (0%)]\tLoss: 0.467862\n","Train Epoch: 112 [640/992 (62%)]\tLoss: 0.374720\n","\n","Test set: Average loss: 1.0476, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 113: 0.73\n","增强倍数 8.0\n","Train Epoch: 113 [0/992 (0%)]\tLoss: 0.341405\n","Train Epoch: 113 [640/992 (62%)]\tLoss: 0.406320\n","\n","Test set: Average loss: 0.8649, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 114: 0.73\n","增强倍数 8.0\n","Train Epoch: 114 [0/992 (0%)]\tLoss: 0.332346\n","Train Epoch: 114 [640/992 (62%)]\tLoss: 0.301177\n","\n","Test set: Average loss: 1.0177, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 115: 0.73\n","增强倍数 8.0\n","Train Epoch: 115 [0/992 (0%)]\tLoss: 0.411503\n","Train Epoch: 115 [640/992 (62%)]\tLoss: 0.345788\n","\n","Test set: Average loss: 1.0140, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 116: 0.73\n","增强倍数 8.0\n","Train Epoch: 116 [0/992 (0%)]\tLoss: 0.425277\n","Train Epoch: 116 [640/992 (62%)]\tLoss: 0.218034\n","\n","Test set: Average loss: 0.8298, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 117: 0.73\n","增强倍数 8.0\n","Train Epoch: 117 [0/992 (0%)]\tLoss: 0.341219\n","Train Epoch: 117 [640/992 (62%)]\tLoss: 0.326217\n","\n","Test set: Average loss: 1.0614, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 118: 0.65\n","增强倍数 8.0\n","Train Epoch: 118 [0/992 (0%)]\tLoss: 0.290912\n","Train Epoch: 118 [640/992 (62%)]\tLoss: 0.302030\n","\n","Test set: Average loss: 1.0171, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 119: 0.62\n","增强倍数 8.0\n","Train Epoch: 119 [0/992 (0%)]\tLoss: 0.335288\n","Train Epoch: 119 [640/992 (62%)]\tLoss: 0.396552\n","\n","Test set: Average loss: 0.8083, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 120: 0.73\n","增强倍数 8.0\n","Train Epoch: 120 [0/992 (0%)]\tLoss: 0.292927\n","Train Epoch: 120 [640/992 (62%)]\tLoss: 0.531562\n","\n","Test set: Average loss: 0.9999, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 121: 0.73\n","增强倍数 8.0\n","Train Epoch: 121 [0/992 (0%)]\tLoss: 0.233151\n","Train Epoch: 121 [640/992 (62%)]\tLoss: 0.250198\n","\n","Test set: Average loss: 0.8627, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 122: 0.73\n","增强倍数 8.0\n","Train Epoch: 122 [0/992 (0%)]\tLoss: 0.334616\n","Train Epoch: 122 [640/992 (62%)]\tLoss: 0.290598\n","\n","Test set: Average loss: 1.0200, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 123: 0.73\n","增强倍数 8.0\n","Train Epoch: 123 [0/992 (0%)]\tLoss: 0.197171\n","Train Epoch: 123 [640/992 (62%)]\tLoss: 0.288392\n","\n","Test set: Average loss: 0.9382, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 124: 0.73\n","增强倍数 8.0\n","Train Epoch: 124 [0/992 (0%)]\tLoss: 0.261516\n","Train Epoch: 124 [640/992 (62%)]\tLoss: 0.178683\n","\n","Test set: Average loss: 0.9677, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 125: 0.73\n","增强倍数 8.0\n","Train Epoch: 125 [0/992 (0%)]\tLoss: 0.461069\n","Train Epoch: 125 [640/992 (62%)]\tLoss: 0.209142\n","\n","Test set: Average loss: 0.8955, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 126: 0.77\n","增强倍数 8.0\n","Train Epoch: 126 [0/992 (0%)]\tLoss: 0.281441\n","Train Epoch: 126 [640/992 (62%)]\tLoss: 0.221879\n","\n","Test set: Average loss: 0.9706, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 127: 0.69\n","增强倍数 8.0\n","Train Epoch: 127 [0/992 (0%)]\tLoss: 0.493146\n","Train Epoch: 127 [640/992 (62%)]\tLoss: 0.567771\n","\n","Test set: Average loss: 0.8941, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 128: 0.69\n","增强倍数 8.0\n","Train Epoch: 128 [0/992 (0%)]\tLoss: 0.401036\n","Train Epoch: 128 [640/992 (62%)]\tLoss: 0.565032\n","\n","Test set: Average loss: 0.7573, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 129: 0.73\n","增强倍数 8.0\n","Train Epoch: 129 [0/992 (0%)]\tLoss: 0.481107\n","Train Epoch: 129 [640/992 (62%)]\tLoss: 0.355061\n","\n","Test set: Average loss: 0.6620, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 130: 0.81\n","增强倍数 8.0\n","Train Epoch: 130 [0/992 (0%)]\tLoss: 0.359348\n","Train Epoch: 130 [640/992 (62%)]\tLoss: 0.383111\n","\n","Test set: Average loss: 0.8680, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 131: 0.81\n","增强倍数 8.0\n","Train Epoch: 131 [0/992 (0%)]\tLoss: 0.353678\n","Train Epoch: 131 [640/992 (62%)]\tLoss: 0.307474\n","\n","Test set: Average loss: 0.8468, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 132: 0.77\n","增强倍数 8.0\n","Train Epoch: 132 [0/992 (0%)]\tLoss: 0.479422\n","Train Epoch: 132 [640/992 (62%)]\tLoss: 0.326737\n","\n","Test set: Average loss: 0.7310, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 133: 0.81\n","增强倍数 8.0\n","Train Epoch: 133 [0/992 (0%)]\tLoss: 0.314033\n","Train Epoch: 133 [640/992 (62%)]\tLoss: 0.278348\n","\n","Test set: Average loss: 0.8534, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 134: 0.73\n","增强倍数 8.0\n","Train Epoch: 134 [0/992 (0%)]\tLoss: 0.199133\n","Train Epoch: 134 [640/992 (62%)]\tLoss: 0.264762\n","\n","Test set: Average loss: 0.7965, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 135: 0.77\n","增强倍数 8.0\n","Train Epoch: 135 [0/992 (0%)]\tLoss: 0.257485\n","Train Epoch: 135 [640/992 (62%)]\tLoss: 0.241613\n","\n","Test set: Average loss: 0.9073, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 136: 0.77\n","增强倍数 8.0\n","Train Epoch: 136 [0/992 (0%)]\tLoss: 0.225447\n","Train Epoch: 136 [640/992 (62%)]\tLoss: 0.248563\n","\n","Test set: Average loss: 0.6850, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 137: 0.69\n","增强倍数 8.0\n","Train Epoch: 137 [0/992 (0%)]\tLoss: 0.357688\n","Train Epoch: 137 [640/992 (62%)]\tLoss: 0.234090\n","\n","Test set: Average loss: 0.7604, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 138: 0.77\n","增强倍数 8.0\n","Train Epoch: 138 [0/992 (0%)]\tLoss: 0.277310\n","Train Epoch: 138 [640/992 (62%)]\tLoss: 0.174174\n","\n","Test set: Average loss: 0.8316, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 139: 0.77\n","增强倍数 8.0\n","Train Epoch: 139 [0/992 (0%)]\tLoss: 0.316573\n","Train Epoch: 139 [640/992 (62%)]\tLoss: 0.254021\n","\n","Test set: Average loss: 0.8546, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 140: 0.73\n","增强倍数 8.0\n","Train Epoch: 140 [0/992 (0%)]\tLoss: 0.132765\n","Train Epoch: 140 [640/992 (62%)]\tLoss: 0.286263\n","\n","Test set: Average loss: 0.7962, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 141: 0.69\n","增强倍数 8.0\n","Train Epoch: 141 [0/992 (0%)]\tLoss: 0.263783\n","Train Epoch: 141 [640/992 (62%)]\tLoss: 0.157861\n","\n","Test set: Average loss: 0.9181, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 142: 0.73\n","增强倍数 8.0\n","Train Epoch: 142 [0/992 (0%)]\tLoss: 0.210352\n","Train Epoch: 142 [640/992 (62%)]\tLoss: 0.219523\n","\n","Test set: Average loss: 1.1212, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 143: 0.77\n","增强倍数 8.0\n","Train Epoch: 143 [0/992 (0%)]\tLoss: 0.130400\n","Train Epoch: 143 [640/992 (62%)]\tLoss: 0.206146\n","\n","Test set: Average loss: 0.9234, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 144: 0.81\n","增强倍数 8.0\n","Train Epoch: 144 [0/992 (0%)]\tLoss: 0.133349\n","Train Epoch: 144 [640/992 (62%)]\tLoss: 0.335663\n","\n","Test set: Average loss: 0.9738, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 145: 0.77\n","增强倍数 8.0\n","Train Epoch: 145 [0/992 (0%)]\tLoss: 0.293629\n","Train Epoch: 145 [640/992 (62%)]\tLoss: 0.228564\n","\n","Test set: Average loss: 0.9567, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 146: 0.65\n","增强倍数 8.0\n","Train Epoch: 146 [0/992 (0%)]\tLoss: 0.227944\n","Train Epoch: 146 [640/992 (62%)]\tLoss: 0.278950\n","\n","Test set: Average loss: 0.9274, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 147: 0.73\n","增强倍数 8.0\n","Train Epoch: 147 [0/992 (0%)]\tLoss: 0.332559\n","Train Epoch: 147 [640/992 (62%)]\tLoss: 0.158673\n","\n","Test set: Average loss: 0.9372, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 148: 0.73\n","增强倍数 8.0\n","Train Epoch: 148 [0/992 (0%)]\tLoss: 0.239944\n","Train Epoch: 148 [640/992 (62%)]\tLoss: 0.159046\n","\n","Test set: Average loss: 1.0271, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 149: 0.65\n","增强倍数 8.0\n","Train Epoch: 149 [0/992 (0%)]\tLoss: 0.266767\n","Train Epoch: 149 [640/992 (62%)]\tLoss: 0.174337\n","\n","Test set: Average loss: 1.0958, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 150: 0.73\n","增强倍数 8.0\n","Train Epoch: 150 [0/992 (0%)]\tLoss: 0.265045\n","Train Epoch: 150 [640/992 (62%)]\tLoss: 0.234989\n","\n","Test set: Average loss: 1.2595, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 151: 0.62\n","增强倍数 8.0\n","Train Epoch: 151 [0/992 (0%)]\tLoss: 0.371783\n","Train Epoch: 151 [640/992 (62%)]\tLoss: 0.338162\n","\n","Test set: Average loss: 1.1003, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 152: 0.65\n","增强倍数 8.0\n","Train Epoch: 152 [0/992 (0%)]\tLoss: 0.265196\n","Train Epoch: 152 [640/992 (62%)]\tLoss: 0.194146\n","\n","Test set: Average loss: 0.9296, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 153: 0.69\n","增强倍数 8.0\n","Train Epoch: 153 [0/992 (0%)]\tLoss: 0.241684\n","Train Epoch: 153 [640/992 (62%)]\tLoss: 0.199243\n","\n","Test set: Average loss: 0.9766, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 154: 0.77\n","增强倍数 8.0\n","Train Epoch: 154 [0/992 (0%)]\tLoss: 0.280691\n","Train Epoch: 154 [640/992 (62%)]\tLoss: 0.217969\n","\n","Test set: Average loss: 1.1154, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 155: 0.73\n","增强倍数 8.0\n","Train Epoch: 155 [0/992 (0%)]\tLoss: 0.149997\n","Train Epoch: 155 [640/992 (62%)]\tLoss: 0.217230\n","\n","Test set: Average loss: 1.1028, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 156: 0.77\n","增强倍数 8.0\n","Train Epoch: 156 [0/992 (0%)]\tLoss: 0.255449\n","Train Epoch: 156 [640/992 (62%)]\tLoss: 0.124895\n","\n","Test set: Average loss: 0.9476, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 157: 0.69\n","增强倍数 8.0\n","Train Epoch: 157 [0/992 (0%)]\tLoss: 0.198345\n","Train Epoch: 157 [640/992 (62%)]\tLoss: 0.144497\n","\n","Test set: Average loss: 0.9687, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 158: 0.77\n","增强倍数 8.0\n","Train Epoch: 158 [0/992 (0%)]\tLoss: 0.239684\n","Train Epoch: 158 [640/992 (62%)]\tLoss: 0.200884\n","\n","Test set: Average loss: 1.0840, Accuracy: 0.62\n","\n","Validation Accuracy after Epoch 159: 0.62\n","增强倍数 8.0\n","Train Epoch: 159 [0/992 (0%)]\tLoss: 0.125330\n","Train Epoch: 159 [640/992 (62%)]\tLoss: 0.245769\n","\n","Test set: Average loss: 1.0159, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 160: 0.69\n","增强倍数 8.0\n","Train Epoch: 160 [0/992 (0%)]\tLoss: 0.252401\n","Train Epoch: 160 [640/992 (62%)]\tLoss: 0.183060\n","\n","Test set: Average loss: 1.0674, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 161: 0.73\n","增强倍数 8.0\n","Train Epoch: 161 [0/992 (0%)]\tLoss: 0.311490\n","Train Epoch: 161 [640/992 (62%)]\tLoss: 0.309420\n","\n","Test set: Average loss: 1.2489, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 162: 0.73\n","增强倍数 8.0\n","Train Epoch: 162 [0/992 (0%)]\tLoss: 0.258328\n","Train Epoch: 162 [640/992 (62%)]\tLoss: 0.319716\n","\n","Test set: Average loss: 1.1506, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 163: 0.73\n","增强倍数 8.0\n","Train Epoch: 163 [0/992 (0%)]\tLoss: 0.185980\n","Train Epoch: 163 [640/992 (62%)]\tLoss: 0.135553\n","\n","Test set: Average loss: 0.9234, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 164: 0.77\n","增强倍数 8.0\n","Train Epoch: 164 [0/992 (0%)]\tLoss: 0.178386\n","Train Epoch: 164 [640/992 (62%)]\tLoss: 0.123969\n","\n","Test set: Average loss: 1.0602, Accuracy: 0.65\n","\n","Validation Accuracy after Epoch 165: 0.65\n","增强倍数 8.0\n","Train Epoch: 165 [0/992 (0%)]\tLoss: 0.436549\n","Train Epoch: 165 [640/992 (62%)]\tLoss: 0.247463\n","\n","Test set: Average loss: 0.9167, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 166: 0.73\n","增强倍数 8.0\n","Train Epoch: 166 [0/992 (0%)]\tLoss: 0.207154\n","Train Epoch: 166 [640/992 (62%)]\tLoss: 0.185237\n","\n","Test set: Average loss: 1.0357, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 167: 0.73\n","增强倍数 8.0\n","Train Epoch: 167 [0/992 (0%)]\tLoss: 0.172525\n","Train Epoch: 167 [640/992 (62%)]\tLoss: 0.192101\n","\n","Test set: Average loss: 0.9551, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 168: 0.77\n","增强倍数 8.0\n","Train Epoch: 168 [0/992 (0%)]\tLoss: 0.255048\n","Train Epoch: 168 [640/992 (62%)]\tLoss: 0.218135\n","\n","Test set: Average loss: 1.0010, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 169: 0.73\n","增强倍数 8.0\n","Train Epoch: 169 [0/992 (0%)]\tLoss: 0.233532\n","Train Epoch: 169 [640/992 (62%)]\tLoss: 0.296770\n","\n","Test set: Average loss: 1.0791, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 170: 0.73\n","增强倍数 8.0\n","Train Epoch: 170 [0/992 (0%)]\tLoss: 0.230867\n","Train Epoch: 170 [640/992 (62%)]\tLoss: 0.146936\n","\n","Test set: Average loss: 1.0024, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 171: 0.73\n","增强倍数 8.0\n","Train Epoch: 171 [0/992 (0%)]\tLoss: 0.197036\n","Train Epoch: 171 [640/992 (62%)]\tLoss: 0.184843\n","\n","Test set: Average loss: 1.0695, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 172: 0.73\n","增强倍数 8.0\n","Train Epoch: 172 [0/992 (0%)]\tLoss: 0.141967\n","Train Epoch: 172 [640/992 (62%)]\tLoss: 0.183270\n","\n","Test set: Average loss: 1.0497, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 173: 0.81\n","增强倍数 8.0\n","Train Epoch: 173 [0/992 (0%)]\tLoss: 0.192453\n","Train Epoch: 173 [640/992 (62%)]\tLoss: 0.162284\n","\n","Test set: Average loss: 0.9819, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 174: 0.73\n","增强倍数 8.0\n","Train Epoch: 174 [0/992 (0%)]\tLoss: 0.155605\n","Train Epoch: 174 [640/992 (62%)]\tLoss: 0.254456\n","\n","Test set: Average loss: 1.0490, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 175: 0.73\n","增强倍数 8.0\n","Train Epoch: 175 [0/992 (0%)]\tLoss: 0.294991\n","Train Epoch: 175 [640/992 (62%)]\tLoss: 0.128277\n","\n","Test set: Average loss: 1.1371, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 176: 0.77\n","增强倍数 8.0\n","Train Epoch: 176 [0/992 (0%)]\tLoss: 0.130076\n","Train Epoch: 176 [640/992 (62%)]\tLoss: 0.315260\n","\n","Test set: Average loss: 1.2399, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 177: 0.69\n","增强倍数 8.0\n","Train Epoch: 177 [0/992 (0%)]\tLoss: 0.153388\n","Train Epoch: 177 [640/992 (62%)]\tLoss: 0.241994\n","\n","Test set: Average loss: 1.1539, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 178: 0.77\n","增强倍数 8.0\n","Train Epoch: 178 [0/992 (0%)]\tLoss: 0.162315\n","Train Epoch: 178 [640/992 (62%)]\tLoss: 0.121637\n","\n","Test set: Average loss: 0.9871, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 179: 0.73\n","增强倍数 8.0\n","Train Epoch: 179 [0/992 (0%)]\tLoss: 0.134656\n","Train Epoch: 179 [640/992 (62%)]\tLoss: 0.109567\n","\n","Test set: Average loss: 1.1603, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 180: 0.73\n","增强倍数 8.0\n","Train Epoch: 180 [0/992 (0%)]\tLoss: 0.075203\n","Train Epoch: 180 [640/992 (62%)]\tLoss: 0.264674\n","\n","Test set: Average loss: 1.3410, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 181: 0.73\n","增强倍数 8.0\n","Train Epoch: 181 [0/992 (0%)]\tLoss: 0.314151\n","Train Epoch: 181 [640/992 (62%)]\tLoss: 0.113552\n","\n","Test set: Average loss: 1.2423, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 182: 0.81\n","增强倍数 8.0\n","Train Epoch: 182 [0/992 (0%)]\tLoss: 0.223191\n","Train Epoch: 182 [640/992 (62%)]\tLoss: 0.205181\n","\n","Test set: Average loss: 1.0626, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 183: 0.73\n","增强倍数 8.0\n","Train Epoch: 183 [0/992 (0%)]\tLoss: 0.212595\n","Train Epoch: 183 [640/992 (62%)]\tLoss: 0.238244\n","\n","Test set: Average loss: 1.0845, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 184: 0.73\n","增强倍数 8.0\n","Train Epoch: 184 [0/992 (0%)]\tLoss: 0.216133\n","Train Epoch: 184 [640/992 (62%)]\tLoss: 0.242206\n","\n","Test set: Average loss: 1.2790, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 185: 0.77\n","增强倍数 8.0\n","Train Epoch: 185 [0/992 (0%)]\tLoss: 0.199433\n","Train Epoch: 185 [640/992 (62%)]\tLoss: 0.140819\n","\n","Test set: Average loss: 1.1046, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 186: 0.77\n","增强倍数 8.0\n","Train Epoch: 186 [0/992 (0%)]\tLoss: 0.146533\n","Train Epoch: 186 [640/992 (62%)]\tLoss: 0.160081\n","\n","Test set: Average loss: 1.0061, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 187: 0.77\n","增强倍数 8.0\n","Train Epoch: 187 [0/992 (0%)]\tLoss: 0.202056\n","Train Epoch: 187 [640/992 (62%)]\tLoss: 0.162491\n","\n","Test set: Average loss: 1.0257, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 188: 0.77\n","增强倍数 8.0\n","Train Epoch: 188 [0/992 (0%)]\tLoss: 0.236800\n","Train Epoch: 188 [640/992 (62%)]\tLoss: 0.249208\n","\n","Test set: Average loss: 1.0716, Accuracy: 0.69\n","\n","Validation Accuracy after Epoch 189: 0.69\n","增强倍数 8.0\n","Train Epoch: 189 [0/992 (0%)]\tLoss: 0.273478\n","Train Epoch: 189 [640/992 (62%)]\tLoss: 0.120576\n","\n","Test set: Average loss: 1.3722, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 190: 0.73\n","增强倍数 8.0\n","Train Epoch: 190 [0/992 (0%)]\tLoss: 0.195947\n","Train Epoch: 190 [640/992 (62%)]\tLoss: 0.147712\n","\n","Test set: Average loss: 1.3842, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 191: 0.73\n","增强倍数 8.0\n","Train Epoch: 191 [0/992 (0%)]\tLoss: 0.118761\n","Train Epoch: 191 [640/992 (62%)]\tLoss: 0.164431\n","\n","Test set: Average loss: 1.0960, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 192: 0.77\n","增强倍数 8.0\n","Train Epoch: 192 [0/992 (0%)]\tLoss: 0.303097\n","Train Epoch: 192 [640/992 (62%)]\tLoss: 0.127618\n","\n","Test set: Average loss: 1.1319, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 193: 0.77\n","增强倍数 8.0\n","Train Epoch: 193 [0/992 (0%)]\tLoss: 0.125913\n","Train Epoch: 193 [640/992 (62%)]\tLoss: 0.160286\n","\n","Test set: Average loss: 1.0635, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 194: 0.73\n","增强倍数 8.0\n","Train Epoch: 194 [0/992 (0%)]\tLoss: 0.233152\n","Train Epoch: 194 [640/992 (62%)]\tLoss: 0.216736\n","\n","Test set: Average loss: 1.2560, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 195: 0.73\n","增强倍数 8.0\n","Train Epoch: 195 [0/992 (0%)]\tLoss: 0.180887\n","Train Epoch: 195 [640/992 (62%)]\tLoss: 0.151563\n","\n","Test set: Average loss: 1.1895, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 196: 0.73\n","增强倍数 8.0\n","Train Epoch: 196 [0/992 (0%)]\tLoss: 0.168786\n","Train Epoch: 196 [640/992 (62%)]\tLoss: 0.277513\n","\n","Test set: Average loss: 1.2579, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 197: 0.77\n","增强倍数 8.0\n","Train Epoch: 197 [0/992 (0%)]\tLoss: 0.133171\n","Train Epoch: 197 [640/992 (62%)]\tLoss: 0.136675\n","\n","Test set: Average loss: 1.0475, Accuracy: 0.77\n","\n","Validation Accuracy after Epoch 198: 0.77\n","增强倍数 8.0\n","Train Epoch: 198 [0/992 (0%)]\tLoss: 0.056931\n","Train Epoch: 198 [640/992 (62%)]\tLoss: 0.195388\n","\n","Test set: Average loss: 1.3442, Accuracy: 0.73\n","\n","Validation Accuracy after Epoch 199: 0.73\n","增强倍数 8.0\n","Train Epoch: 199 [0/992 (0%)]\tLoss: 0.164887\n","Train Epoch: 199 [640/992 (62%)]\tLoss: 0.250674\n","\n","Test set: Average loss: 1.1833, Accuracy: 0.81\n","\n","Validation Accuracy after Epoch 200: 0.81\n","\n","Test set: Average loss: 0.2889, Accuracy: 0.94\n","\n","Final Test Accuracy: 0.94\n"]}],"source":["#进行全部数据增强的\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.nn.functional import softmax\n","import random\n","import torch.nn.functional as F\n","import os\n","from torch.utils.data import DataLoader, ConcatDataset\n","\n","# 设定种子以确保可重复性\n","torch.manual_seed(42)\n","random.seed(42)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 定义LSTM模型\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(LSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        # Reshape input to (batch_size, sequence_length, input_size)\n","        x = x.view(x.size(0), x.size(3), -1).permute(0, 2, 1)\n","\n","        out, _ = self.lstm(x)\n","        out = self.fc(out[:, -1, :])  # 取最后一个时间步的输出\n","        return out\n","\n","# 数据增强\n","def data_augmentation(dataset):\n","    # 使用 torchvision 提供的数据增强方法\n","    transform = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    transform1 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","    ])\n","    transform2 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    transform3 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomHorizontalFlip()\n","    ])\n","    transform4 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","        transforms.RandomHorizontalFlip()\n","    ])\n","    transform5 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    transform6 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform\n","    )\n","\n","    combined_dataset = ConcatDataset([dataset, augmented_dataset])  # 将原数据集和增强后的数据集合并\n","\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform1\n","    )\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform2\n","    )\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform3\n","    )\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform4\n","    )\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform5\n","    )\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform6\n","    )\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","\n","    return combined_dataset\n","\n","# 训练模型\n","def train(model, train_loader, criterion, optimizer, epoch, device):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 10 == 0:\n","            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n","                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n","\n","# 测试模型\n","def test(model, test_loader, device):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","\n","            output = model(data)\n","            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n","\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    accuracy = correct / len(test_loader.dataset)\n","    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}\\n')\n","\n","    return test_loss, accuracy\n","\n","# 数据集路径\n","dataset_path = '/content/drive/MyDrive/城市工程系统智能化/attention_augmented'\n","\n","# 定义转换\n","transform = transforms.Compose([transforms.Resize((32, 32)),\n","                                transforms.ToTensor()])\n","\n","# 创建数据集和数据加载器\n","train_dataset = datasets.ImageFolder(root=os.path.join(dataset_path,'train'), transform=transform)\n","val_dataset = datasets.ImageFolder(root=os.path.join(dataset_path,'val'), transform=transform)\n","test_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, 'test'), transform=transform)\n","\n","# 数据加载器\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n","\n","# 初始化模型、损失函数和优化器\n","input_size = 32  # 输入的大小，根据你的数据集调整\n","hidden_size = 64  # LSTM隐藏层的大小，根据需要调整\n","num_classes = 5  # 类别数，根据你的数据集调整\n","model = LSTMModel(input_size, hidden_size, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","test_dataset_path = os.path.join(dataset_path, 'test')\n","final_test_dataset = datasets.ImageFolder(root=test_dataset_path, transform=transform)\n","final_test_loader = DataLoader(final_test_dataset, batch_size=64, shuffle=True)\n","# 训练10个epoch\n","\n","for epoch in range(200):\n","    enhanced_train_dataset = data_augmentation(train_dataset)\n","\n","    print('增强倍数',len(enhanced_train_dataset) / len(train_dataset))\n","    # 创建新的 DataLoader 对象，使用 enhanced_train_dataset2\n","    enhanced_train_loader = DataLoader(enhanced_train_dataset, batch_size=64, shuffle=True)\n","\n","    # 继续训练\n","    train(model, enhanced_train_loader, criterion, optimizer, epoch, device)\n","\n","    # 在验证集上进行测试\n","    val_loss, val_accuracy = test(model, val_loader, device)\n","    print(f'Validation Accuracy after Epoch {epoch + 1}: {val_accuracy:.2f}')\n","\n","# 在整个测试集上进行最终测试\n","final_test_loss, final_test_accuracy = test(model, test_loader, device)\n","print(f'Final Test Accuracy: {final_test_accuracy:.2f}')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":30497,"status":"error","timestamp":1704768571841,"user":{"displayName":"liu rongchuan","userId":"03500046369369319821"},"user_tz":-480},"id":"WYF-yRKaolrd","outputId":"c7cbbf04-f719-4cc7-c581-d19f8f5a5196"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Epoch: 0 [0/42 (0%)]\tLoss: 1.608069\n","\n","Test set: Average loss: 1.6127, Accuracy: 0.21\n","\n","Validation Accuracy after Epoch 1: 0.21\n","enhancement_ratios1= tensor([0.2208, 0.1756, 0.2014, 0.2098, 0.1923])\n","num_classes: 2\n","len(concat_dataset): 336\n","Train Epoch: 0 [0/78 (0%)]\tLoss: 1.681096\n","\n","Test set: Average loss: 1.6179, Accuracy: 0.21\n","\n","Validation Accuracy after Epoch 1: 0.21\n","enhancement_ratios2= tensor([0.2088, 0.1732, 0.2061, 0.2205, 0.1914])\n","num_classes: 2\n","len(concat_dataset): 320\n","Train Epoch: 0 [0/71 (0%)]\tLoss: 1.632756\n","Train Epoch: 1 [0/42 (0%)]\tLoss: 1.601045\n","\n","Test set: Average loss: 1.6303, Accuracy: 0.21\n","\n","Validation Accuracy after Epoch 2: 0.21\n","enhancement_ratios1= tensor([0.1890, 0.1680, 0.2134, 0.2389, 0.1906])\n","num_classes: 2\n","len(concat_dataset): 336\n","Train Epoch: 1 [0/78 (0%)]\tLoss: 1.562863\n","\n","Test set: Average loss: 1.6422, Accuracy: 0.14\n","\n","Validation Accuracy after Epoch 2: 0.14\n","enhancement_ratios2= tensor([0.1750, 0.1644, 0.2185, 0.2521, 0.1899])\n","num_classes: 2\n","len(concat_dataset): 320\n","Train Epoch: 1 [0/71 (0%)]\tLoss: 1.529643\n","Train Epoch: 2 [0/42 (0%)]\tLoss: 1.617100\n","\n","Test set: Average loss: 1.6685, Accuracy: 0.21\n","\n","Validation Accuracy after Epoch 3: 0.21\n","enhancement_ratios1= tensor([0.1518, 0.1577, 0.2275, 0.2745, 0.1886])\n","num_classes: 2\n","len(concat_dataset): 336\n","Train Epoch: 2 [0/78 (0%)]\tLoss: 1.422629\n","\n","Test set: Average loss: 1.6944, Accuracy: 0.21\n","\n","Validation Accuracy after Epoch 3: 0.21\n","enhancement_ratios2= tensor([0.1346, 0.1528, 0.2344, 0.2911, 0.1871])\n","num_classes: 2\n","len(concat_dataset): 320\n","Train Epoch: 2 [0/71 (0%)]\tLoss: 1.381601\n","Train Epoch: 3 [0/42 (0%)]\tLoss: 1.677881\n","\n","Test set: Average loss: 1.7569, Accuracy: 0.21\n","\n","Validation Accuracy after Epoch 4: 0.21\n","enhancement_ratios1= tensor([0.1048, 0.1450, 0.2468, 0.3197, 0.1838])\n","num_classes: 2\n","len(concat_dataset): 336\n","Train Epoch: 3 [0/78 (0%)]\tLoss: 1.225059\n","\n","Test set: Average loss: 1.8152, Accuracy: 0.21\n","\n","Validation Accuracy after Epoch 4: 0.21\n","enhancement_ratios2= tensor([0.0846, 0.1390, 0.2566, 0.3386, 0.1812])\n","num_classes: 2\n","len(concat_dataset): 320\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-12-7a53ab7431ec\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 409\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0menhanced_train_dataset3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_augmentation3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 512\u001b[0;31m     \u001b[0menhanced_train_dataset33\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_samples_from_concat_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menhanced_train_dataset3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menhancement_ratios\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;31m# 创建新的 DataLoader 对象，使用 enhanced_train_dataset2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0menhanced_train_loader3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menhanced_train_dataset33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-12-7a53ab7431ec\u003e\u001b[0m in \u001b[0;36mextract_samples_from_concat_dataset\u001b[0;34m(concat_dataset, sampling_ratios)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mclass_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 367\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples_per_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-12-7a53ab7431ec\u003e\u001b[0m in \u001b[0;36m\u003clistcomp\u003e\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mclass_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 367\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples_per_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 229\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 246\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#进行注意力增强的全部文件夹的生成\n","#本代码实现的功能为生成完全进行数据增强的train_dataset2和train_dataset3,需要配合下面独立开出的代码使用。\n","#下面的代码主要完成的任务是，利用增强比，从这些数据集中抽取图像数据用于训练\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Subset, ConcatDataset\n","from torchvision import datasets, transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.nn.functional import softmax\n","import random\n","import torch.nn.functional as F\n","import os\n","import numpy as np\n","\n","\n","# 设定种子以确保可重复性\n","torch.manual_seed(42)\n","random.seed(42)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 定义LSTM模型\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(LSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        # Reshape input to (batch_size, sequence_length, input_size)\n","        x = x.view(x.size(0), x.size(3), -1).permute(0, 2, 1)\n","\n","        out, _ = self.lstm(x)\n","        out = self.fc(out[:, -1, :])  # 取最后一个时间步的输出\n","        return out\n","\n","# 数据增强\n","def data_augmentation2(dataset):\n","    save_path = 'train_dataset2'\n","    # 使用 torchvision 提供的数据增强方法\n","    transform = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    transform1 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","    ])\n","    transform2 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    transform3 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomHorizontalFlip()\n","    ])\n","    transform4 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","        transforms.RandomHorizontalFlip()\n","    ])\n","    transform5 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    transform6 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    #1\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform\n","    )\n","    # Save dataset\n","    os.makedirs(save_path, exist_ok=True)\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_1_{i}.jpg'))\n","\n","    combined_dataset = ConcatDataset([dataset, augmented_dataset])  # 将原数据集和增强后的数据集合并\n","    #2\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform1\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_2_{i}.jpg'))\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","    #3\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform2\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_3_{i}.jpg'))\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","    #4\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform3\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_4_{i}.jpg'))\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","    #5\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform4\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_5_{i}.jpg'))\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","    #6\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform5\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_6_{i}.jpg'))\n","\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","    #7\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform6\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_7_{i}.jpg'))\n","\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","\n","    return combined_dataset\n","def data_augmentation3(dataset):\n","    save_path = 'train_dataset3'\n","    # 使用 torchvision 提供的数据增强方法\n","    transform = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    transform1 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","    ])\n","    transform2 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    transform3 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomHorizontalFlip()\n","    ])\n","    transform4 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","        transforms.RandomHorizontalFlip()\n","    ])\n","    transform5 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomRotation(degrees=15),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    transform6 = transforms.Compose([\n","        transforms.Resize((32, 32)),  # 调整为相同的大小\n","        transforms.ToTensor(),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n","    ])\n","    #1\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform\n","    )\n","    # Save dataset\n","    os.makedirs(save_path, exist_ok=True)\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_1_{i}.jpg'))\n","\n","    combined_dataset = ConcatDataset([dataset, augmented_dataset])  # 将原数据集和增强后的数据集合并\n","    #2\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform1\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_2_{i}.jpg'))\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","    #3\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform2\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_3_{i}.jpg'))\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","    #4\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform3\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_4_{i}.jpg'))\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","    #5\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform4\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_5_{i}.jpg'))\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","    #6\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform5\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_6_{i}.jpg'))\n","\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","    #7\n","    augmented_dataset = datasets.ImageFolder(\n","        root=dataset.root,\n","        transform=transform6\n","    )\n","    # Save dataset\n","    for i, (image_tensor, label) in enumerate(augmented_dataset):\n","        class_name = dataset.classes[label]\n","        class_path = os.path.join(save_path, class_name)\n","        os.makedirs(class_path, exist_ok=True)\n","        image = transforms.ToPILImage()(image_tensor)\n","        image.save(os.path.join(class_path, f'image_7_{i}.jpg'))\n","\n","    combined_dataset = ConcatDataset([combined_dataset, augmented_dataset])\n","\n","    return combined_dataset\n","\n","# 训练模型\n","def train(model, train_loader, criterion, optimizer, epoch, device):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 10 == 0:\n","            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n","                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n","\n","# 测试模型\n","def test(model, test_loader, device):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","\n","            output = model(data)\n","            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n","\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    accuracy = correct / len(test_loader.dataset)\n","    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}\\n')\n","\n","    return test_loss, accuracy\n","\n","def extract_samples_from_concat_dataset(concat_dataset, sampling_ratios):\n","    num_classes = len(concat_dataset.datasets)\n","    print(\"num_classes:\",num_classes)\n","    print('len(concat_dataset):',len(concat_dataset))\n","    # 定义每个类别的抽取数量\n","    num_samples_per_class = (sampling_ratios/ sampling_ratios.max() * len(concat_dataset)).int()\n","\n","    # 创建新的 Subset 数据集\n","    new_datasets = []\n","    for class_idx in range(num_classes):\n","        class_dataset = concat_dataset.datasets[class_idx]\n","        indices = torch.tensor([i for i, (_, label) in enumerate(class_dataset) if label == class_idx])\n","        num_samples = min(num_samples_per_class[class_idx], len(indices))\n","\n","        if num_samples \u003e 0:\n","            selected_indices = torch.randint(0, len(indices), size=(num_samples,))\n","            selected_indices = indices[selected_indices]\n","            new_dataset = Subset(class_dataset, selected_indices)\n","            new_datasets.append(new_dataset)\n","\n","    # 创建新的 ConcatDataset\n","    new_concat_dataset = ConcatDataset(new_datasets)\n","\n","    return new_concat_dataset\n","\n","# 数据集路径\n","dataset_path = '/content/drive/MyDrive/城市工程系统智能化/attention_augmented1'\n","\n","# 创建数据集和数据加载器\n","transform = transforms.Compose([transforms.Resize((32, 32)),\n","                                transforms.ToTensor()])\n","train_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, 'train', 'train_set1'), transform=transform)\n","train_dataset2 = datasets.ImageFolder(root=os.path.join(dataset_path, 'train', 'train_set2'), transform=transform)\n","#print(train_dataset2)\n","#print(len(train_dataset2.classes))\n","train_dataset3 = datasets.ImageFolder(root=os.path.join(dataset_path, 'train', 'train_set3'), transform=transform)\n","val_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, 'val'), transform=transform)\n","test_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, 'test'), transform=transform)\n","\n","# 数据加载器\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n","\n","# 初始化模型、损失函数和优化器\n","input_size = 32  # 输入的大小，根据你的数据集调整\n","hidden_size = 64  # LSTM隐藏层的大小，根据需要调整\n","num_classes = 5  # 类别数，根据你的数据集调整\n","model = LSTMModel(input_size, hidden_size, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# 训练10个epoch\n","for epoch in range(30):\n","    # 对第一个拆分后的子训练集进行训练\n","    train(model, train_loader, criterion, optimizer, epoch, device)\n","\n","    # 在验证集上进行测试\n","    val_loss, val_accuracy = test(model, val_loader, device)\n","    print(f'Validation Accuracy after Epoch {epoch + 1}: {val_accuracy:.2f}')\n","\n","    # 获取每个类别的损失值\n","    class_losses = [0] * num_classes\n","    class_counts = [0] * num_classes\n","    with torch.no_grad():\n","        for data, target in val_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = F.cross_entropy(output, target, reduction='none')\n","            for i in range(num_classes):\n","                mask = target == i\n","                class_losses[i] += loss[mask].sum().item()\n","                class_counts[i] += mask.sum().item()\n","\n","    # 求得损失值的softmax作为增强比\n","    enhancement_ratios = softmax(torch.tensor(class_losses) / torch.tensor(class_counts), dim=0)\n","    print('enhancement_ratios1=',enhancement_ratios)\n","    # 对第二个划分的子训练集进行数据增强\n","    enhanced_train_dataset2 = data_augmentation2(train_dataset2)\n","\n","    enhanced_train_dataset22 = extract_samples_from_concat_dataset(enhanced_train_dataset2, enhancement_ratios)\n","\n","    # 创建新的 DataLoader 对象，使用 enhanced_train_dataset2\n","    enhanced_train_loader2 = DataLoader(enhanced_train_dataset22, batch_size=64, shuffle=True)\n","    '''\n","    num_samples_per_class = (enhancement_ratios * len(enhanced_train_dataset2)).int()\n","\n","    # 创建新的 Subset 数据集\n","    new_datasets = []\n","    for class_idx in range(5):\n","        # 遍历每个子数据集\n","        for dataset_idx, folder_dataset in enumerate(enhanced_train_dataset2.datasets):\n","            # 计算该子数据集对应的类别的样本数量\n","            num_samples = int(num_samples_per_class[class_idx] / len(enhanced_train_dataset2))  # 平均分配到每个子数据集\n","\n","            # 随机选择相应数量的样本\n","            indices = torch.randperm(len(folder_dataset))\n","            selected_indices = indices[:num_samples]\n","\n","            # 创建新的 Subset 数据集\n","            new_dataset = Subset(folder_dataset, selected_indices)\n","            new_datasets.append(new_dataset)\n","\n","    # 创建新的 ConcatDataset\n","    enhanced_train_dataset22 = ConcatDataset(new_datasets)\n","\n","\n","\n","\n","\n","    enhanced_train_dataset22 = datasets.ImageFolder(root=os.path.join(dataset_path, 'train', 'train_set2'), transform=transform)\n","\n","    for i, (root, dirs, files) in enumerate(os.walk(os.path.join(dataset_path, 'train', 'train_set2'))):\n","        if i == 0:  # 跳过主目录\n","            continue\n","        class_name = os.path.basename(root)\n","        class_label = train_dataset2.class_to_idx[class_name]\n","        class_count = int(enhancement_ratios[class_label].item() * len(files))\n","        selected_files = random.sample(files, class_count)\n","\n","        for file in selected_files:\n","            file_path = os.path.join(root, file)\n","            enhanced_train_dataset22.samples.append((file_path, class_label))\n","\n","    # 创建新的 DataLoader 对象，使用 enhanced_train_dataset22\n","    enhanced_train_loader22 = DataLoader(enhanced_train_dataset22, batch_size=64, shuffle=True)\n","\n","    # 继续训练\n","    train(model, enhanced_train_loader22, criterion, optimizer, epoch, device)\n","    '''\n","    # 继续训练\n","    train(model, enhanced_train_loader2, criterion, optimizer, epoch, device)\n","\n","    # 在验证集上进行测试\n","    val_loss, val_accuracy = test(model, val_loader, device)\n","    print(f'Validation Accuracy after Epoch {epoch + 1}: {val_accuracy:.2f}')\n","\n","    # 获取每个类别的损失值\n","    class_losses = [0] * num_classes\n","    class_counts = [0] * num_classes\n","    with torch.no_grad():\n","        for data, target in val_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = F.cross_entropy(output, target, reduction='none')\n","            for i in range(num_classes):\n","                mask = target == i\n","                class_losses[i] += loss[mask].sum().item()\n","                class_counts[i] += mask.sum().item()\n","\n","    # 求得损失值的softmax作为增强比\n","    enhancement_ratios = softmax(torch.tensor(class_losses) / torch.tensor(class_counts), dim=0)\n","    print('enhancement_ratios2=',enhancement_ratios)\n","    # 对第二个划分的子训练集进行数据增强\n","    enhanced_train_dataset3 = data_augmentation3(train_dataset3)\n","\n","    enhanced_train_dataset33 = extract_samples_from_concat_dataset(enhanced_train_dataset3, enhancement_ratios)\n","    # 创建新的 DataLoader 对象，使用 enhanced_train_dataset2\n","    enhanced_train_loader3 = DataLoader(enhanced_train_dataset33, batch_size=64, shuffle=True)\n","\n","    # 继续训练\n","    train(model, enhanced_train_loader3, criterion, optimizer, epoch, device)\n","\n","# 在整个测试集上进行最终测试\n","final_test_loss, final_test_accuracy = test(model, test_loader, device)\n","print(f'Final Test Accuracy: {final_test_accuracy:.2f}')\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":397,"status":"ok","timestamp":1704768405313,"user":{"displayName":"liu rongchuan","userId":"03500046369369319821"},"user_tz":-480},"id":"Vxt6pOVVHLeX"},"outputs":[],"source":["#本代码用于删除固定路径的文件\n","import shutil\n","save_path = 'train_dataset2'\n","shutil.rmtree(save_path)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"elapsed":624,"status":"error","timestamp":1704778642280,"user":{"displayName":"liu rongchuan","userId":"03500046369369319821"},"user_tz":-480},"id":"5ZgWQHycIWzs"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Epoch: 0 [0/42 (0%)]\tLoss: 1.608069\n","\n","Test set: Average loss: 1.6127, Accuracy: 0.21\n","\n","Validation Accuracy after Epoch 1: 0.21\n","enhancement_ratios1= tensor([1.0000, 0.7953, 0.9120, 0.9503, 0.8711])\n","num_classes: 5\n","len(concat_dataset): 294\n","[56, 56, 56, 70, 56]\n","tensor([56, 44, 51, 66, 48], dtype=torch.int32)\n","class_idx= 0\n","/content/drive/MyDrive/城市工程系统智能化/train_dataset2/black soil\n"]},{"ename":"AttributeError","evalue":"'enumerate' object has no attribute 'label'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-53-66ca6909e1c6\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 152\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enhancement_ratios1='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menhancement_ratios\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0menhancement_ratios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;31m# 对第二个划分的子训练集进行数据增强\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 177\u001b[0;31m     \u001b[0menhanced_train_dataset22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_samples_from_concat_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset22\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/城市工程系统智能化/train_dataset2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menhancement_ratios\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;31m# 创建新的 DataLoader 对象，使用 enhanced_train_dataset2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-53-66ca6909e1c6\u003e\u001b[0m in \u001b[0;36mextract_samples_from_concat_dataset\u001b[0;34m(concat_dataset, dataset_path, sampling_ratios)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mclass_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m#class_dataset = datasets.ImageFolder(concat_dataset.root + '/' + class_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 107\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enumerate(class_dataset).label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'enumerate' object has no attribute 'label'"]}],"source":["#完成基于注意力机制的数据增强的训练\n","#根据增强比从这些数据集中抽取图像数据用于训练\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Subset, ConcatDataset\n","from torchvision import datasets, transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.nn.functional import softmax\n","import random\n","import torch.nn.functional as F\n","import os\n","import numpy as np\n","\n","\n","# 设定种子以确保可重复性\n","torch.manual_seed(42)\n","random.seed(42)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 定义LSTM模型\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(LSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        # Reshape input to (batch_size, sequence_length, input_size)\n","        x = x.view(x.size(0), x.size(3), -1).permute(0, 2, 1)\n","\n","        out, _ = self.lstm(x)\n","        out = self.fc(out[:, -1, :])  # 取最后一个时间步的输出\n","        return out\n","\n","# 训练模型\n","def train(model, train_loader, criterion, optimizer, epoch, device):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 10 == 0:\n","            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n","                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n","\n","# 测试模型\n","def test(model, test_loader, device):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","\n","            output = model(data)\n","            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n","\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    accuracy = correct / len(test_loader.dataset)\n","    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}\\n')\n","\n","    return test_loss, accuracy\n","def count_images_per_class(dataset_path):\n","    class_folders = [folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))]\n","\n","    image_counts = []\n","\n","    for class_folder in class_folders:\n","        class_path = os.path.join(dataset_path, class_folder, class_folder)\n","        images = [file for file in os.listdir(class_path) if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n","        image_counts.append(len(images))\n","\n","    return image_counts\n","\n","def extract_samples_from_concat_dataset(concat_dataset, dataset_path, sampling_ratios):\n","    num_classes = len(concat_dataset.classes)\n","    print(\"num_classes:\", num_classes)\n","    print('len(concat_dataset):', len(concat_dataset))\n","    print(count_images_per_class(dataset_path))\n","    #\n","    # Define the number of samples to extract per class\n","    num_samples_per_class = (sampling_ratios / sampling_ratios.max() * torch.tensor(count_images_per_class(dataset_path))).int()\n","    print(num_samples_per_class)\n","\n","    # Create new Subset datasets\n","    new_datasets = []\n","    for class_idx in range(num_classes):\n","        print('class_idx=',class_idx)  #输出后发现class_idx的输出为0、1、2、3、4,而下方的label应该也和其相对应\n","        transform = transforms.Compose([\n","                                transforms.ToTensor()])\n","        class_path = concat_dataset.classes[class_idx]\n","        class_folder = os.path.join(concat_dataset.root, class_path)\n","        print(class_folder)\n","        class_dataset = datasets.ImageFolder(class_folder, transform=transform)\n","        #class_dataset = datasets.ImageFolder(concat_dataset.root + '/' + class_path)\n","        print('class_dataset.label',class_dataset.label)\n","        indices = torch.tensor([i for i, (_, label) in enumerate(class_dataset) if label == class_idx])\n","        print(indices)\n","        num_samples = min(num_samples_per_class[class_idx], len(indices))\n","        print('num_samples=',num_samples)\n","        print('len(indices)=',len(indices))\n","\n","        if num_samples \u003e 0:\n","            selected_indices = torch.randint(0, len(indices), size=(num_samples,))\n","            selected_indices = indices[selected_indices]\n","            new_dataset = Subset(class_dataset, selected_indices)\n","            new_datasets.append(new_dataset)\n","\n","    # Create new ConcatDataset\n","    new_concat_dataset = ConcatDataset(new_datasets)\n","\n","    return new_concat_dataset\n","# 数据集路径\n","dataset_path = '/content/drive/MyDrive/城市工程系统智能化/attention_augmented1'\n","\n","# 创建数据集和数据加载器\n","transform = transforms.Compose([transforms.Resize((32, 32)),\n","                                transforms.ToTensor()])\n","train_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, 'train', 'train_set1'), transform=transform)\n","#train_dataset2 = datasets.ImageFolder(root=os.path.join(dataset_path, 'train', 'train_set2'), transform=transform)\n","train_dataset22 = datasets.ImageFolder(root=os.path.join('/content/drive/MyDrive/城市工程系统智能化/train_dataset2'), transform=transform)\n","#train_dataset3 = datasets.ImageFolder(root=os.path.join(dataset_path, 'train', 'train_set3'), transform=transform)\n","train_dataset33 = datasets.ImageFolder(root=os.path.join('/content/drive/MyDrive/城市工程系统智能化/train_dataset3'), transform=transform)\n","val_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, 'val'), transform=transform)\n","test_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, 'test'), transform=transform)\n","\n","# 数据加载器\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n","\n","# 初始化模型、损失函数和优化器\n","input_size = 32  # 输入的大小，根据你的数据集调整\n","hidden_size = 64  # LSTM隐藏层的大小，根据需要调整\n","num_classes = 5  # 类别数，根据你的数据集调整\n","model = LSTMModel(input_size, hidden_size, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# 训练10个epoch\n","for epoch in range(200):\n","    # 对第一个拆分后的子训练集进行训练\n","    train(model, train_loader, criterion, optimizer, epoch, device)\n","\n","    # 在验证集上进行测试\n","    val_loss, val_accuracy = test(model, val_loader, device)\n","    print(f'Validation Accuracy after Epoch {epoch + 1}: {val_accuracy:.2f}')\n","\n","    # 获取每个类别的损失值\n","    class_losses = [0] * num_classes\n","    class_counts = [0] * num_classes\n","    with torch.no_grad():\n","        for data, target in val_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = F.cross_entropy(output, target, reduction='none')\n","            for i in range(num_classes):\n","                mask = target == i\n","                class_losses[i] += loss[mask].sum().item()\n","                class_counts[i] += mask.sum().item()\n","\n","    # 求得损失值的softmax作为增强比\n","    enhancement_ratios = softmax(torch.tensor(class_losses) / torch.tensor(class_counts), dim=0)\n","    print('enhancement_ratios1=',enhancement_ratios/ enhancement_ratios.max())\n","    # 对第二个划分的子训练集进行数据增强\n","    enhanced_train_dataset22 = extract_samples_from_concat_dataset(train_dataset22, '/content/drive/MyDrive/城市工程系统智能化/train_dataset2',enhancement_ratios)\n","\n","    # 创建新的 DataLoader 对象，使用 enhanced_train_dataset2\n","    enhanced_train_loader2 = DataLoader(enhanced_train_dataset22, batch_size=64, shuffle=True)\n","\n","    # 继续训练\n","    train(model, enhanced_train_loader2, criterion, optimizer, epoch, device)\n","\n","    # 在验证集上进行测试\n","    val_loss, val_accuracy = test(model, val_loader, device)\n","    print(f'Validation Accuracy after Epoch {epoch + 1}: {val_accuracy:.2f}')\n","\n","    # 获取每个类别的损失值\n","    class_losses = [0] * num_classes\n","    class_counts = [0] * num_classes\n","    with torch.no_grad():\n","        for data, target in val_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = F.cross_entropy(output, target, reduction='none')\n","            for i in range(num_classes):\n","                mask = target == i\n","                class_losses[i] += loss[mask].sum().item()\n","                class_counts[i] += mask.sum().item()\n","\n","    # 求得损失值的softmax作为增强比\n","    enhancement_ratios = softmax(torch.tensor(class_losses) / torch.tensor(class_counts), dim=0)\n","    print('enhancement_ratios2=',enhancement_ratios/ enhancement_ratios.max())\n","    # 对第二个划分的子训练集进行数据增强\n","    enhanced_train_dataset33 = extract_samples_from_concat_dataset(train_dataset33,'/content/drive/MyDrive/城市工程系统智能化/train_dataset3', enhancement_ratios)\n","    # 创建新的 DataLoader 对象，使用 enhanced_train_dataset2\n","    enhanced_train_loader3 = DataLoader(enhanced_train_dataset33, batch_size=64, shuffle=True)\n","\n","    # 继续训练\n","    train(model, enhanced_train_loader3, criterion, optimizer, epoch, device)\n","\n","# 在整个测试集上进行最终测试\n","final_test_loss, final_test_accuracy = test(model, test_loader, device)\n","print(f'Final Test Accuracy: {final_test_accuracy:.2f}')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMCA1oIpTL1KKKGmGf5vQm6","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}